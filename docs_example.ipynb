{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with GPT-3.5-turbo, GPT-4, and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset is 1,200 DS related job posting from Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/data_science_jobs_indeed_usa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.assign(token_count=df['Description'].apply(lambda x: len(encoding.encode(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IT Business Intelligence Developer (FT) Remote...</td>\n",
       "      <td>Ballad Health</td>\n",
       "      <td>Remote in Blountville, TN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Details Apply Save Print this job Email a…</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=58612836c63b8...</td>\n",
       "      <td>Job Details\\nApply\\nSave\\nPrint this job\\nEmai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Longevity Holdings Inc.</td>\n",
       "      <td>Remote in Minneapolis-Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 3 days ago</td>\n",
       "      <td>$90,000 - $110,000 a year</td>\n",
       "      <td>Incorporate core data management competencies ...</td>\n",
       "      <td>https://www.indeed.com/company/TwentyFirst/job...</td>\n",
       "      <td>Position: Data Engineer\\nLocation: MN\\nAs a Da...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Network Administrator/dba developer</td>\n",
       "      <td>WKI Kenworth</td>\n",
       "      <td>Wichita, KS 67219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EmployerActive 2 days ago</td>\n",
       "      <td>$50,000 - $70,000 a year</td>\n",
       "      <td>The Network Administrator provides 2nd level e...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Full Job Description\\nThe Network Administrato...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                                     Data Scientist   \n",
       "1           1                                   Business Analyst   \n",
       "2           2  IT Business Intelligence Developer (FT) Remote...   \n",
       "3           3                                      Data Engineer   \n",
       "4           4                Network Administrator/dba developer   \n",
       "\n",
       "                   Company                              Location  Rating  \\\n",
       "0            Driven Brands                           Benicia, CA     2.4   \n",
       "1         Sabot Consulting                                Remote     NaN   \n",
       "2            Ballad Health             Remote in Blountville, TN     3.0   \n",
       "3  Longevity Holdings Inc.  Remote in Minneapolis-Saint Paul, MN     NaN   \n",
       "4             WKI Kenworth                     Wichita, KS 67219     NaN   \n",
       "\n",
       "                        Date                     Salary  \\\n",
       "0   PostedPosted 26 days ago                        NaN   \n",
       "1    PostedPosted 4 days ago         $80 - $120 an hour   \n",
       "2  PostedPosted 30+ days ago                        NaN   \n",
       "3    PostedPosted 3 days ago  $90,000 - $110,000 a year   \n",
       "4  EmployerActive 2 days ago   $50,000 - $70,000 a year   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "2     Job Details Apply Save Print this job Email a…   \n",
       "3  Incorporate core data management competencies ...   \n",
       "4  The Network Administrator provides 2nd level e...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "2  https://www.indeed.com/rc/clk?jk=58612836c63b8...   \n",
       "3  https://www.indeed.com/company/TwentyFirst/job...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                        Descriptions  token_count  \n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26  \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25  \n",
       "2  Job Details\\nApply\\nSave\\nPrint this job\\nEmai...           10  \n",
       "3  Position: Data Engineer\\nLocation: MN\\nAs a Da...           29  \n",
       "4  Full Job Description\\nThe Network Administrato...           28  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure: \n",
    "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "# def get_embedding(text) -> list[float]:\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "#     return openai.Embedding.create(input=text, engine=OpenAiEmbedding)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "# def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "#    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.assign(embedding=df['Description'].apply(lambda x: get_embedding(x, model='text-embedding-ada-002')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_parquet(\"job_descriptions_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"job_descriptions_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IT Business Intelligence Developer (FT) Remote...</td>\n",
       "      <td>Ballad Health</td>\n",
       "      <td>Remote in Blountville, TN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Details Apply Save Print this job Email a…</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=58612836c63b8...</td>\n",
       "      <td>Job Details\\nApply\\nSave\\nPrint this job\\nEmai...</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.021908748894929886, -0.002960818586871028,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Longevity Holdings Inc.</td>\n",
       "      <td>Remote in Minneapolis-Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 3 days ago</td>\n",
       "      <td>$90,000 - $110,000 a year</td>\n",
       "      <td>Incorporate core data management competencies ...</td>\n",
       "      <td>https://www.indeed.com/company/TwentyFirst/job...</td>\n",
       "      <td>Position: Data Engineer\\nLocation: MN\\nAs a Da...</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.017482835799455643, -0.01076465379446745, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Network Administrator/dba developer</td>\n",
       "      <td>WKI Kenworth</td>\n",
       "      <td>Wichita, KS 67219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EmployerActive 2 days ago</td>\n",
       "      <td>$50,000 - $70,000 a year</td>\n",
       "      <td>The Network Administrator provides 2nd level e...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Full Job Description\\nThe Network Administrato...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0011034636991098523, -0.000915585900656879,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                                     Data Scientist   \n",
       "1           1                                   Business Analyst   \n",
       "2           2  IT Business Intelligence Developer (FT) Remote...   \n",
       "3           3                                      Data Engineer   \n",
       "4           4                Network Administrator/dba developer   \n",
       "\n",
       "                   Company                              Location  Rating  \\\n",
       "0            Driven Brands                           Benicia, CA     2.4   \n",
       "1         Sabot Consulting                                Remote     NaN   \n",
       "2            Ballad Health             Remote in Blountville, TN     3.0   \n",
       "3  Longevity Holdings Inc.  Remote in Minneapolis-Saint Paul, MN     NaN   \n",
       "4             WKI Kenworth                     Wichita, KS 67219     NaN   \n",
       "\n",
       "                        Date                     Salary  \\\n",
       "0   PostedPosted 26 days ago                       None   \n",
       "1    PostedPosted 4 days ago         $80 - $120 an hour   \n",
       "2  PostedPosted 30+ days ago                       None   \n",
       "3    PostedPosted 3 days ago  $90,000 - $110,000 a year   \n",
       "4  EmployerActive 2 days ago   $50,000 - $70,000 a year   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "2     Job Details Apply Save Print this job Email a…   \n",
       "3  Incorporate core data management competencies ...   \n",
       "4  The Network Administrator provides 2nd level e...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "2  https://www.indeed.com/rc/clk?jk=58612836c63b8...   \n",
       "3  https://www.indeed.com/company/TwentyFirst/job...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "2  Job Details\\nApply\\nSave\\nPrint this job\\nEmai...           10   \n",
       "3  Position: Data Engineer\\nLocation: MN\\nAs a Da...           29   \n",
       "4  Full Job Description\\nThe Network Administrato...           28   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...  \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...  \n",
       "2  [-0.021908748894929886, -0.002960818586871028,...  \n",
       "3  [-0.017482835799455643, -0.01076465379446745, ...  \n",
       "4  [0.0011034636991098523, -0.000915585900656879,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df.embedding.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `n_clusters=6` is arbitrary & just for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df['kmeans_label'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Title           Company     Location  Rating  \\\n",
       "0           0    Data Scientist     Driven Brands  Benicia, CA     2.4   \n",
       "1           1  Business Analyst  Sabot Consulting       Remote     NaN   \n",
       "\n",
       "                       Date              Salary  \\\n",
       "0  PostedPosted 26 days ago                None   \n",
       "1   PostedPosted 4 days ago  $80 - $120 an hour   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "\n",
       "                                           embedding  kmeans_label  \n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4  \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...             2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_parquet(\"ClusterLabelerTestResults.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# res_df = pd.read_parquet(\"ClusterLabelerTestResults.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import langchain\n",
    "# from langchain.cache import SQLiteCache\n",
    "# langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "system_template = \"You're an expert journalist. You're helping me write a concise topic title for job descriptions.\"\n",
    "human_template = \"Using the following job description, write a concise tag line.\\n\\nDESCRIPTIONS:{Description}\\n\\nTAG LINE:\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        HumanMessagePromptTemplate.from_template(human_template),\n",
    "    ],\n",
    "    input_variables=[\"Description\"],\n",
    ")\n",
    "    \n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), prompt=prompt, verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_chain = df[[\"Description\"]].to_dict('records')\n",
    "len(list_to_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': 'You’ll be working alongside a team of eight analysts & data scientists - collaborating to design datasets, develop analytical models & provide insights.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_chain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = asyncio.Semaphore(50)\n",
    "\n",
    "async def delay_wrapper(func, *args, **kwargs):\n",
    "    async with sem:\n",
    "        result = await func(*args, **kwargs)\n",
    "    await asyncio.sleep(2)  # 2 second delay\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_index.token_catcher import Usage\n",
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 12. Elapsed time: 4.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out.\n",
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 2 of 12. Elapsed time: 607.80 seconds\n",
      "Processed batch 3 of 12. Elapsed time: 3.91 seconds\n",
      "Processed batch 4 of 12. Elapsed time: 4.56 seconds\n",
      "Processed batch 5 of 12. Elapsed time: 4.01 seconds\n",
      "Processed batch 6 of 12. Elapsed time: 3.28 seconds\n",
      "Processed batch 7 of 12. Elapsed time: 3.64 seconds\n",
      "Processed batch 8 of 12. Elapsed time: 3.88 seconds\n",
      "Processed batch 9 of 12. Elapsed time: 3.95 seconds\n",
      "Processed batch 10 of 12. Elapsed time: 3.42 seconds\n",
      "Processed batch 11 of 12. Elapsed time: 4.17 seconds\n",
      "Processed batch 12 of 12. Elapsed time: 3.24 seconds\n",
      "Total elapsed time: 650.01 seconds\n",
      "Tokens used: 0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "result = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, batch_start in enumerate(range(0, len(list_to_chain), batch_size)):\n",
    "    batch_start_time = time.time()\n",
    "    batch = list_to_chain[batch_start: batch_start + batch_size]\n",
    "    processed_batch = await delay_wrapper(chain.aapply, batch)\n",
    "    result.append(processed_batch)\n",
    "    elapsed_time = time.time() - batch_start_time\n",
    "    print(f\"Processed batch {i + 1} of {len(list_to_chain) // batch_size}. Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "final_time = time.time() - start_time\n",
    "print(f\"Total elapsed time: {final_time:.2f} seconds\")\n",
    "print(f\"Tokens used: {usage.total_tokens():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\"Join our dynamic team of analysts and data scientists to drive data-driven insights and innovation.\"'},\n",
       " {'text': '\"Experienced Cloud Migration Specialist for SAAS Implementations\"'},\n",
       " {'text': '\"Exciting Job Opportunity: Apply Now for a Rewarding Career!\"'},\n",
       " {'text': '\"Data Management Expert: Ensuring Governance, Security, and Quality\"'},\n",
       " {'text': '\"Experienced Network Administrator: Expert in SQL, Linux, Debian, and Arduino\"'},\n",
       " {'text': '\"Data Science Expert: Driving Business Outcomes and Patient Impact\"'},\n",
       " {'text': 'Experienced Data Engineer: Expertise in Report Development, Data Science, and Business Analytics'},\n",
       " {'text': '\"Experienced Developer: Data Conversions and Consultative Support\"'},\n",
       " {'text': '\"Leading the Way in Data Science: Hiring, Training, and Retaining Top Talent\"'},\n",
       " {'text': '\"Experienced Data Science Leader: Building and Leading High-Performing Teams\"'},\n",
       " {'text': '\"Data Analysis Expert with Proven Experience in Designing and Implementing End-to-End Data Pipelines\"'},\n",
       " {'text': '\"Data Lake Expert with Oracle and SQL Experience\"'},\n",
       " {'text': '\"Experienced Data Scientist with Strong Statistical and AI Expertise\"'},\n",
       " {'text': '\"Driving Data Science and Analytics Success: Define and Execute a Strategic Roadmap\"'},\n",
       " {'text': 'Experienced Data Science Manager for Technology Company'},\n",
       " {'text': '\"Data Scientist: Leveraging AI and ML for Methodological Excellence\"'},\n",
       " {'text': 'Experienced Data Science Team Leader: Oversee and Drive Technical Projects'},\n",
       " {'text': 'Data and AI/ML Expert for Strategic Communications and Project Planning'},\n",
       " {'text': 'Enhancing CRM Personalization and Targeting through Collaboration'},\n",
       " {'text': '\"Collaborative Engineering Opportunity with Ezoic, a Google Certified Publishing Partner\"'},\n",
       " {'text': '\"Data-driven insights for informed decision-making\"'},\n",
       " {'text': '\"Experienced Data Professional with Expertise in Traditional Data Warehousing and Confluent Kafka Data Pipelines\"'},\n",
       " {'text': '\"Data Scientist: Uncovering Insights from Complex Clinical Data\"'},\n",
       " {'text': '\"Expertise in Data Mining and Machine Learning: Unleash the Power of Modern Techniques\"'},\n",
       " {'text': '\"Data-driven problem solving and process optimization for enhanced product performance\"'},\n",
       " {'text': '\"Seeking candidates with interactive machine learning experience (active learning, reinforcement learning, machine teaching preferred)\"'},\n",
       " {'text': '\"Spring Health: Breaking Barriers to Mental Health\"'},\n",
       " {'text': 'Data Pipeline Manager: Scaling and Enhancing Data Quality for Product Launches'},\n",
       " {'text': '\"Experienced Database Administrator: Oracle, Optimization, and Schema Design\"'},\n",
       " {'text': 'Experienced Database Manager in Epic Cachè'},\n",
       " {'text': '\"Empowering Business Growth with Citizen Development: No Code, Low Code Techniques for Requirements Management\"'},\n",
       " {'text': '\"Configuration Specifications and Business Analysis Expert\"'},\n",
       " {'text': '\"Seeking a Machine Learning Expert with Advanced Analytical Skills and Proficiency in Frameworks\"'},\n",
       " {'text': '\"Business Intelligence Developer: Creating Analytical Reports and Dashboards for Data Monitoring and Process Optimization\"'},\n",
       " {'text': '\"Business Intelligence Developer: Creating Analytical Reports and Dashboards for Data Monitoring and Process Optimization\"'},\n",
       " {'text': '\"Experienced BI Professional: Creating Complex Reports and Dashboards\"'},\n",
       " {'text': '\"Experienced Software Developer with Expertise in Event-Based Streaming\"'},\n",
       " {'text': '\"Expertly applying subject expertise to deliver innovative solutions while adhering to policies and procedures\"'},\n",
       " {'text': '\"Experienced Data Analyst with Strong SQL and Data Integration Skills\"'},\n",
       " {'text': 'Business Requirement Analyst: Driving Solutions for Business Needs'},\n",
       " {'text': 'Data System Guidance and Support for Quality System Compliance'},\n",
       " {'text': '\"Data Support and Quality Assurance Specialist\"'},\n",
       " {'text': '\"Data Sourcing and Management: Expanding and optimizing data resources for enhanced insights\"'},\n",
       " {'text': '\"Business Analyst: Bridging the Gap Between Stakeholders and Developers\"'},\n",
       " {'text': '\"Database Optimization Specialist: Maximizing Performance and Efficiency\"'},\n",
       " {'text': '\"Streamline Data Science Workflows for Efficiency and Scalability\"'},\n",
       " {'text': '\"Data Analytics Solutions Developer - NY-based opportunity to solve business challenges\"'},\n",
       " {'text': '\"Driving Analytic Initiatives for Business Success\"'},\n",
       " {'text': '\"Database Maintenance and Content Review Specialist\"'},\n",
       " {'text': '\"Business Analyst: Collaborate, Analyze, Design\"'},\n",
       " {'text': '\"Experienced Data Scientist proficient in analytics and data visualization tools\"'},\n",
       " {'text': '\"Experienced Data Scientist with a Statistical Edge\"'},\n",
       " {'text': '\"Collaborative Data Engineer: Designing and Deploying Machine Learning Tools for Enterprise Data\"'},\n",
       " {'text': '\"Data-driven efficiency and targeting strategist\"'},\n",
       " {'text': '\"Database Performance Enhancement and Security Expert\"'},\n",
       " {'text': '\"Data-driven expert sought for Cash App, skilled in querying and analyzing large datasets.\"'},\n",
       " {'text': '\"Seeking a top-tier machine learning engineer to enhance our ML systems\"'},\n",
       " {'text': 'Data Collaboration Specialist: Bridging the Gap Between Science, Engineering, and Research'},\n",
       " {'text': '\"Transforming Objectives into Actionable Insights: Leveraging Machine Learning for Business Optimization\"'},\n",
       " {'text': '\"Operational support for MSFT Azure database management and data storage\"'},\n",
       " {'text': '\"Business Intelligence Solutions Expert: Enhancing Processes with Data-driven Reports\"'},\n",
       " {'text': 'Data Integration and Analysis Support Specialist'},\n",
       " {'text': '\"Empowering Retail Success through Data Science and Engineering Solutions\"'},\n",
       " {'text': '\"Data Engineer: Expertise in Scala, Spark, SQL, Hadoop, AWS, and CI/CD\"'},\n",
       " {'text': '\"Automating Data Tasks: Collaborating with Engineers for Efficiency\"'},\n",
       " {'text': '\"Seeking Data Analytics and Machine Learning Expert for Expanding Machine Intelligence Capabilities\"'},\n",
       " {'text': '\"Seeking a tech enthusiast passionate about embedded integration, computer vision, and machine learning.\"'},\n",
       " {'text': 'Experienced Data Scientist: Collaborate and Analyze Data Architecture'},\n",
       " {'text': '\"Expert in Database Backup and Recovery Processes\"'},\n",
       " {'text': '\"Seeking a Data Science Expert with a Strong Analytical Background\"'},\n",
       " {'text': '\"Data Extraction and Infrastructure Specialist\"'},\n",
       " {'text': 'Experienced Physical DBA: Installation, Creation, Upgrades, Maintenance'},\n",
       " {'text': '\"Data Profiling and Integration Expert: Designing, Deploying, and Supporting Seamless Data Solutions\"'},\n",
       " {'text': '\"Experienced Data Scientist to Lead and Execute Projects from Start to Finish\"'},\n",
       " {'text': '\"Immediate opening for Machine Learning Engineer with expertise in object detection, deep learning, and modeling\"'},\n",
       " {'text': '\"Data Science Expert: Leading Best Practices and Managing Large-Scale Projects\"'},\n",
       " {'text': '\"Database Systems Certification and Operational Readiness: Ensuring Efficiency and Security\"'},\n",
       " {'text': '\"Join our dynamic team of data scientists, engineers, and clinicians to solve complex problems collaboratively.\"'},\n",
       " {'text': '\"Flexible Remote Work with SAP Business Objects Expertise\"'},\n",
       " {'text': 'Experienced Business Process Designer and Builder'},\n",
       " {'text': '\"Expert Data Engineer: Building Modern Data Pipelines and APIs with Effective Monitoring\"'},\n",
       " {'text': '\"Machine Learning Expert for Ad Recommendation and Personalization\"'},\n",
       " {'text': '\"Advanced Database Administrator Opportunity: Dive into Cutting-Edge Technologies\"'},\n",
       " {'text': '\"Data Profiling and Integration Expert: Designing, Deploying, and Supporting Seamless Data Solutions\"'},\n",
       " {'text': '\"Expert in deploying machine learning models with PyTorch and TensorFlow/Keras\"'},\n",
       " {'text': 'Data Architect and QA Specialist'},\n",
       " {'text': '\"Database Administrator: Maximizing Performance and Minimizing Downtime\"'},\n",
       " {'text': '\"Scaling Data Science Services: Deploying and Productizing Machine Learning at Scale\"'},\n",
       " {'text': '\"Data Science Expert: Driving Actionable Insights and Modern Practices\"'},\n",
       " {'text': '\"Driving outcomes through People Analytics & Insights at Cardinal Health\"'},\n",
       " {'text': 'Data Science Point of Contact with Algorithm Expertise'},\n",
       " {'text': '\"Multiple Locations, One Opportunity: Join our Sales & Marketing Team!\"'},\n",
       " {'text': '\"Data System Guidance and Support for Quality System Compliance\"'},\n",
       " {'text': '\"Business Requirements Specialist: Streamlining Processes and Enhancing Systems\"'},\n",
       " {'text': '\"Client Service Expert with Proactive Approach and Positive Attitude\"'},\n",
       " {'text': '\"Scientific Methods Expert: Creating Impactful Insights through Experimentation and Machine Learning\"'},\n",
       " {'text': '\"Join our team and tackle complex problems in NLP, machine learning, and information retrieval!\"'},\n",
       " {'text': '\"Full-time Onsite Position in Bloomfield, CT: Relocation or Commute Required\"'},\n",
       " {'text': '\"Transforming Teradata BTEQ scripts into Informatica mappings/workflows: Join our team of BI-ETL developers!\"'},\n",
       " {'text': '\"Business Requirement Writer: Supporting Data Engineering Excellence\"'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list\n",
    "results = [item for sublist in result for item in sublist]\n",
    "\n",
    "# Check if 'result' length is same as the original data\n",
    "assert len(results) == len(df), \"Length of the result does not match with the original data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"Join our dynamic team of analysts and data scientists to drive data-driven insights and innovation.\"'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llm_title'] = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_parquet(\"cluster_test_llm_titles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"cluster_test_llm_titles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>llm_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Join our dynamic team of analysts and data sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Title        Company     Location  Rating  \\\n",
       "0           0  Data Scientist  Driven Brands  Benicia, CA     2.4   \n",
       "\n",
       "                       Date Salary  \\\n",
       "0  PostedPosted 26 days ago   None   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "\n",
       "                                           embedding  kmeans_label  \\\n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4   \n",
       "\n",
       "                                           llm_title  \n",
       "0  \"Join our dynamic team of analysts and data sc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 551/1200 [06:49<08:30,  1.27it/s]Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      " 64%|██████▍   | 766/1200 [19:36<05:03,  1.43it/s]    Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "100%|██████████| 1200/1200 [34:54<00:00,  1.75s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 2094.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 1\n",
    "result_slow = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, batch_start in tqdm(enumerate(range(0, len(list_to_chain), batch_size)), total=len(list_to_chain)//batch_size):\n",
    "    try:\n",
    "        batch = list_to_chain[batch_start: batch_start + batch_size]\n",
    "        processed_batch = chain.run(batch)\n",
    "        result_slow.append(processed_batch)\n",
    "    # replace Exception with list of actual errors\n",
    "    except Exception as e:\n",
    "        result_slow.append({'text': str(e)})\n",
    "        \n",
    "   \n",
    "final_time = time.time() - start_time\n",
    "print(f\"Total elapsed time: {final_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>llm_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Join our dynamic team of analysts and data sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Experienced Cloud Migration Specialist for SA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Title           Company     Location  Rating  \\\n",
       "0           0    Data Scientist     Driven Brands  Benicia, CA     2.4   \n",
       "1           1  Business Analyst  Sabot Consulting       Remote     NaN   \n",
       "\n",
       "                       Date              Salary  \\\n",
       "0  PostedPosted 26 days ago                None   \n",
       "1   PostedPosted 4 days ago  $80 - $120 an hour   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "\n",
       "                                           embedding  kmeans_label  \\\n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4   \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...             2   \n",
       "\n",
       "                                           llm_title  \n",
       "0  \"Join our dynamic team of analysts and data sc...  \n",
       "1  \"Experienced Cloud Migration Specialist for SA...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_template_string = \"\"\"The following is a list of job descriptions.\n",
    "{descriptions}\n",
    "\n",
    "Based on this list of descriptions, please do 2 things: \n",
    "(1) identify groups of similar jobs\n",
    "(2) give a concise title for each group\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_template_string = template = \"\"\"The following is a list of job titles:\n",
    "{titles}\n",
    "\n",
    "Take these and write a concise job title that summarizes them. Respond with a single string using 5 words or less. \n",
    "\n",
    "TITLE:\"\"\"\n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"descriptions\"], template=map_template_string)\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"titles\"], template=reduce_template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mr(input_doc, MAP_PROMPT, REDUCE_PROMPT):\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    reduce_llm_chain = LLMChain(llm=llm, prompt=REDUCE_PROMPT)\n",
    "\n",
    "    # Takes a list of documents and combines them into a single string\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "            llm_chain=reduce_llm_chain,\n",
    "            document_variable_name=\"titles\")\n",
    "    \n",
    "    # Combines and iteravely reduces the mapped documents \n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `combine_documents_chain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=4000)\n",
    "\n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    combine_documents = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_llm_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"descriptions\",\n",
    "        # Return the results of the map steps in the output\n",
    "        ### Bug: this currently does not work ###\n",
    "        return_intermediate_steps=False)\n",
    "        \n",
    "    # Define Map=Reduce\n",
    "    map_reduce = MapReduceChain(\n",
    "        # Chain to combine documents\n",
    "        combine_documents_chain=combine_documents,\n",
    "        # Splitter to use for initial split\n",
    "        text_splitter=text_splitter)\n",
    "    \n",
    "    return map_reduce.run(input_text=input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n",
      "Tokens Used: 43,018\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "usage = Usage()\n",
    "\n",
    "for c in df.kmeans_label.unique():\n",
    "\n",
    "    descriptions_str = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"{article['Description']}\\n\"\n",
    "            for article in df.query(f\"kmeans_label == {c}\").to_dict(orient=\"records\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    result = run_mr(descriptions_str, MAP_PROMPT, REDUCE_PROMPT)\n",
    "    \n",
    "    df.loc[df.kmeans_label == c, \"topic_title_\"] = result\n",
    "    \n",
    "print(f\"Tokens Used: {usage.total_tokens():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_title\n",
       "Data Science and Analytics Roles                                  555\n",
       "Business Analysis and Intelligence Professionals                  211\n",
       "Machine Learning and AI Job Roles                                 180\n",
       "Database Administrator and Performance Optimization Specialist    146\n",
       "IT and Data Professionals                                         108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_title_\n",
       "Data Science and Strategy Manager              281\n",
       "Data Science and Analytics Specialist          274\n",
       "Business Analyst and Intelligence Developer    211\n",
       "Machine Learning Expert                        180\n",
       "Database Specialist                            146\n",
       "Cloud Migration Specialist                     108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic_title_.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kmeans_label\n",
       "4    281\n",
       "3    274\n",
       "5    211\n",
       "1    180\n",
       "0    146\n",
       "2    108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.kmeans_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>llm_title</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>topic_title_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Join our dynamic team of analysts and data sc...</td>\n",
       "      <td>Data Science and Analytics Roles</td>\n",
       "      <td>Data Science and Strategy Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Experienced Cloud Migration Specialist for SA...</td>\n",
       "      <td>IT and Data Professionals</td>\n",
       "      <td>Cloud Migration Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IT Business Intelligence Developer (FT) Remote...</td>\n",
       "      <td>Ballad Health</td>\n",
       "      <td>Remote in Blountville, TN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Details Apply Save Print this job Email a…</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=58612836c63b8...</td>\n",
       "      <td>Job Details\\nApply\\nSave\\nPrint this job\\nEmai...</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.021908748894929886, -0.002960818586871028,...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Exciting Job Opportunity: Apply Now for a Rew...</td>\n",
       "      <td>IT and Data Professionals</td>\n",
       "      <td>Cloud Migration Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Longevity Holdings Inc.</td>\n",
       "      <td>Remote in Minneapolis-Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 3 days ago</td>\n",
       "      <td>$90,000 - $110,000 a year</td>\n",
       "      <td>Incorporate core data management competencies ...</td>\n",
       "      <td>https://www.indeed.com/company/TwentyFirst/job...</td>\n",
       "      <td>Position: Data Engineer\\nLocation: MN\\nAs a Da...</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.017482835799455643, -0.01076465379446745, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Data Management Expert: Ensuring Governance, ...</td>\n",
       "      <td>Data Science and Analytics Roles</td>\n",
       "      <td>Data Science and Strategy Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Network Administrator/dba developer</td>\n",
       "      <td>WKI Kenworth</td>\n",
       "      <td>Wichita, KS 67219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EmployerActive 2 days ago</td>\n",
       "      <td>$50,000 - $70,000 a year</td>\n",
       "      <td>The Network Administrator provides 2nd level e...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Full Job Description\\nThe Network Administrato...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0011034636991098523, -0.000915585900656879,...</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Experienced Network Administrator: Expert in ...</td>\n",
       "      <td>Database Administrator and Performance Optimiz...</td>\n",
       "      <td>Database Specialist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                                     Data Scientist   \n",
       "1           1                                   Business Analyst   \n",
       "2           2  IT Business Intelligence Developer (FT) Remote...   \n",
       "3           3                                      Data Engineer   \n",
       "4           4                Network Administrator/dba developer   \n",
       "\n",
       "                   Company                              Location  Rating  \\\n",
       "0            Driven Brands                           Benicia, CA     2.4   \n",
       "1         Sabot Consulting                                Remote     NaN   \n",
       "2            Ballad Health             Remote in Blountville, TN     3.0   \n",
       "3  Longevity Holdings Inc.  Remote in Minneapolis-Saint Paul, MN     NaN   \n",
       "4             WKI Kenworth                     Wichita, KS 67219     NaN   \n",
       "\n",
       "                        Date                     Salary  \\\n",
       "0   PostedPosted 26 days ago                       None   \n",
       "1    PostedPosted 4 days ago         $80 - $120 an hour   \n",
       "2  PostedPosted 30+ days ago                       None   \n",
       "3    PostedPosted 3 days ago  $90,000 - $110,000 a year   \n",
       "4  EmployerActive 2 days ago   $50,000 - $70,000 a year   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "2     Job Details Apply Save Print this job Email a…   \n",
       "3  Incorporate core data management competencies ...   \n",
       "4  The Network Administrator provides 2nd level e...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "2  https://www.indeed.com/rc/clk?jk=58612836c63b8...   \n",
       "3  https://www.indeed.com/company/TwentyFirst/job...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "2  Job Details\\nApply\\nSave\\nPrint this job\\nEmai...           10   \n",
       "3  Position: Data Engineer\\nLocation: MN\\nAs a Da...           29   \n",
       "4  Full Job Description\\nThe Network Administrato...           28   \n",
       "\n",
       "                                           embedding  kmeans_label  \\\n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4   \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...             2   \n",
       "2  [-0.021908748894929886, -0.002960818586871028,...             2   \n",
       "3  [-0.017482835799455643, -0.01076465379446745, ...             4   \n",
       "4  [0.0011034636991098523, -0.000915585900656879,...             0   \n",
       "\n",
       "                                           llm_title  \\\n",
       "0  \"Join our dynamic team of analysts and data sc...   \n",
       "1  \"Experienced Cloud Migration Specialist for SA...   \n",
       "2  \"Exciting Job Opportunity: Apply Now for a Rew...   \n",
       "3  \"Data Management Expert: Ensuring Governance, ...   \n",
       "4  \"Experienced Network Administrator: Expert in ...   \n",
       "\n",
       "                                         topic_title  \\\n",
       "0                   Data Science and Analytics Roles   \n",
       "1                          IT and Data Professionals   \n",
       "2                          IT and Data Professionals   \n",
       "3                   Data Science and Analytics Roles   \n",
       "4  Database Administrator and Performance Optimiz...   \n",
       "\n",
       "                        topic_title_  \n",
       "0  Data Science and Strategy Manager  \n",
       "1         Cloud Migration Specialist  \n",
       "2         Cloud Migration Specialist  \n",
       "3  Data Science and Strategy Manager  \n",
       "4                Database Specialist  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    node = TextNode(text=row['Descriptions'],\n",
    "                            id_=f\"anchordata_idx_{index}\",\n",
    "                            metadata={\"Summary\": row['llm_title'],\n",
    "                                      \"Title\": row['Title'],\n",
    "                                      \"Company\": row['Company'],\n",
    "                                      \"Location\": row['Location'],\n",
    "                                      \"Group Name\": row['topic_title']})\n",
    "    nodes.append(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    ")\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "\n",
    "llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embed_model = LangchainEmbedding(\n",
    "    OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    "    chunk_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import QueryBundle\n",
    "from llama_index import QueryBundle\n",
    "\n",
    "# import NodeWithScore\n",
    "from llama_index.schema import NodeWithScore\n",
    "\n",
    "# Retrievers\n",
    "from llama_index.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever,\n",
    "    KeywordTableSimpleRetriever,\n",
    ")\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that performs both semantic search and hybrid search.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_retriever: VectorIndexRetriever,\n",
    "        keyword_retriever: KeywordTableSimpleRetriever,\n",
    "        mode: str = \"AND\",\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "\n",
    "        self._vector_retriever = vector_retriever\n",
    "        self._keyword_retriever = keyword_retriever\n",
    "        if mode not in (\"AND\", \"OR\"):\n",
    "            raise ValueError(\"Invalid mode.\")\n",
    "        self._mode = mode\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query.\"\"\"\n",
    "\n",
    "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
    "        keyword_nodes = self._keyword_retriever.retrieve(query_bundle)\n",
    "\n",
    "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "        keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
    "\n",
    "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "        combined_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
    "\n",
    "        if self._mode == \"AND\":\n",
    "            retrieve_ids = vector_ids.intersection(keyword_ids)\n",
    "        else:\n",
    "            retrieve_ids = vector_ids.union(keyword_ids)\n",
    "\n",
    "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
    "        return retrieve_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import get_response_synthesizer\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# define custom retriever\n",
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=10)\n",
    "keyword_retriever = KeywordTableSimpleRetriever(index=keyword_index)\n",
    "custom_retriever = CustomRetriever(vector_retriever, keyword_retriever)\n",
    "\n",
    "# define response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "custom_query_engine = RetrieverQueryEngine(\n",
    "    retriever=custom_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# vector query engine\n",
    "vector_query_engine = RetrieverQueryEngine(\n",
    "    retriever=vector_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "# keyword query engine\n",
    "keyword_query_engine = RetrieverQueryEngine(\n",
    "    retriever=keyword_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.keyword_table.retrievers:> Starting query: What are some jobs in management that are Remote?\n",
      "> Starting query: What are some jobs in management that are Remote?\n",
      "> Starting query: What are some jobs in management that are Remote?\n",
      "INFO:llama_index.indices.keyword_table.retrievers:query keywords: ['management', 'jobs', 'remote']\n",
      "query keywords: ['management', 'jobs', 'remote']\n",
      "query keywords: ['management', 'jobs', 'remote']\n",
      "INFO:llama_index.indices.keyword_table.retrievers:> Extracted keywords: ['management', 'remote']\n",
      "> Extracted keywords: ['management', 'remote']\n",
      "> Extracted keywords: ['management', 'remote']\n"
     ]
    }
   ],
   "source": [
    "response = custom_query_engine.query(\"What are some jobs in management that are Remote?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Remote Project Manager\n",
      "2. Remote Product Manager\n",
      "3. Remote Operations Manager\n",
      "4. Remote Business Development Manager\n",
      "5. Remote Human Resources Manager\n",
      "6. Remote Quality Assurance Manager\n",
      "7. Remote Financial Manager\n",
      "8. Remote Marketing Manager\n",
      "9. Remote Sales Manager\n",
      "10. Remote IT Manager\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index import ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LlamaDebugHandler to print the trace of the sub questions\n",
    "# captured by the SUB_QUESTION callback event type\n",
    "\n",
    "llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embed_model = LangchainEmbedding(\n",
    "    OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    "    chunk_size=1024,\n",
    "    callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_embedding ->  0.197334 seconds\n",
      "    |_embedding ->  0.2072 seconds\n",
      "    |_embedding ->  0.412453 seconds\n",
      "    |_embedding ->  0.267314 seconds\n",
      "    |_embedding ->  0.294713 seconds\n",
      "    |_embedding ->  0.298592 seconds\n",
      "    |_embedding ->  0.340853 seconds\n",
      "    |_embedding ->  0.527856 seconds\n",
      "    |_embedding ->  0.347137 seconds\n",
      "    |_embedding ->  0.227518 seconds\n",
      "    |_embedding ->  0.325264 seconds\n",
      "    |_embedding ->  0.219555 seconds\n",
      "    |_embedding ->  0.220645 seconds\n",
      "    |_embedding ->  0.373602 seconds\n",
      "    |_embedding ->  0.44774 seconds\n",
      "    |_embedding ->  0.24762 seconds\n",
      "    |_embedding ->  0.384562 seconds\n",
      "    |_embedding ->  0.228622 seconds\n",
      "    |_embedding ->  0.159505 seconds\n",
      "    |_embedding ->  0.232922 seconds\n",
      "    |_embedding ->  0.246764 seconds\n",
      "    |_embedding ->  0.204765 seconds\n",
      "    |_embedding ->  0.210807 seconds\n",
      "    |_embedding ->  0.205868 seconds\n",
      "    |_embedding ->  0.245324 seconds\n",
      "    |_embedding ->  0.249035 seconds\n",
      "    |_embedding ->  0.320555 seconds\n",
      "    |_embedding ->  0.180789 seconds\n",
      "    |_embedding ->  0.226737 seconds\n",
      "    |_embedding ->  0.201446 seconds\n",
      "    |_embedding ->  0.231198 seconds\n",
      "    |_embedding ->  0.382962 seconds\n",
      "    |_embedding ->  0.189049 seconds\n",
      "    |_embedding ->  0.244542 seconds\n",
      "    |_embedding ->  0.197787 seconds\n",
      "    |_embedding ->  0.218617 seconds\n",
      "    |_embedding ->  0.240917 seconds\n",
      "    |_embedding ->  0.230126 seconds\n",
      "    |_embedding ->  0.251161 seconds\n",
      "    |_embedding ->  0.208383 seconds\n",
      "    |_embedding ->  0.222904 seconds\n",
      "    |_embedding ->  0.359535 seconds\n",
      "    |_embedding ->  0.205705 seconds\n",
      "    |_embedding ->  0.334996 seconds\n",
      "    |_embedding ->  0.212973 seconds\n",
      "    |_embedding ->  0.1837 seconds\n",
      "    |_embedding ->  0.232051 seconds\n",
      "    |_embedding ->  0.219428 seconds\n",
      "    |_embedding ->  0.183588 seconds\n",
      "    |_embedding ->  0.23249 seconds\n",
      "    |_embedding ->  0.252261 seconds\n",
      "    |_embedding ->  0.190953 seconds\n",
      "    |_embedding ->  0.185567 seconds\n",
      "    |_embedding ->  0.316083 seconds\n",
      "    |_embedding ->  0.331308 seconds\n",
      "    |_embedding ->  0.210003 seconds\n",
      "    |_embedding ->  0.360348 seconds\n",
      "    |_embedding ->  0.219854 seconds\n",
      "    |_embedding ->  0.329482 seconds\n",
      "    |_embedding ->  0.207405 seconds\n",
      "    |_embedding ->  0.199176 seconds\n",
      "    |_embedding ->  0.27701 seconds\n",
      "    |_embedding ->  0.224692 seconds\n",
      "    |_embedding ->  0.291791 seconds\n",
      "    |_embedding ->  0.320731 seconds\n",
      "    |_embedding ->  0.202689 seconds\n",
      "    |_embedding ->  0.234844 seconds\n",
      "    |_embedding ->  0.22056 seconds\n",
      "    |_embedding ->  0.393461 seconds\n",
      "    |_embedding ->  0.228045 seconds\n",
      "    |_embedding ->  0.301425 seconds\n",
      "    |_embedding ->  0.24917 seconds\n",
      "    |_embedding ->  0.30874 seconds\n",
      "    |_embedding ->  0.224934 seconds\n",
      "    |_embedding ->  0.195884 seconds\n",
      "    |_embedding ->  0.272644 seconds\n",
      "    |_embedding ->  0.333972 seconds\n",
      "    |_embedding ->  0.229392 seconds\n",
      "    |_embedding ->  0.214496 seconds\n",
      "    |_embedding ->  0.328667 seconds\n",
      "    |_embedding ->  0.249851 seconds\n",
      "    |_embedding ->  0.35737 seconds\n",
      "    |_embedding ->  0.216927 seconds\n",
      "    |_embedding ->  0.304454 seconds\n",
      "    |_embedding ->  0.224064 seconds\n",
      "    |_embedding ->  0.250069 seconds\n",
      "    |_embedding ->  0.385548 seconds\n",
      "    |_embedding ->  0.228567 seconds\n",
      "    |_embedding ->  0.242894 seconds\n",
      "    |_embedding ->  0.325655 seconds\n",
      "    |_embedding ->  0.202343 seconds\n",
      "    |_embedding ->  0.39276 seconds\n",
      "    |_embedding ->  0.36169 seconds\n",
      "    |_embedding ->  0.337486 seconds\n",
      "    |_embedding ->  0.212213 seconds\n",
      "    |_embedding ->  0.3388 seconds\n",
      "    |_embedding ->  0.398911 seconds\n",
      "    |_embedding ->  0.842811 seconds\n",
      "    |_embedding ->  0.371306 seconds\n",
      "    |_embedding ->  0.392804 seconds\n",
      "    |_embedding ->  0.425934 seconds\n",
      "    |_embedding ->  0.198474 seconds\n",
      "    |_embedding ->  0.183889 seconds\n",
      "    |_embedding ->  0.291493 seconds\n",
      "    |_embedding ->  0.191754 seconds\n",
      "    |_embedding ->  0.29829 seconds\n",
      "    |_embedding ->  0.211052 seconds\n",
      "    |_embedding ->  0.350298 seconds\n",
      "    |_embedding ->  0.328729 seconds\n",
      "    |_embedding ->  0.303176 seconds\n",
      "    |_embedding ->  0.371608 seconds\n",
      "    |_embedding ->  0.52443 seconds\n",
      "    |_embedding ->  0.193675 seconds\n",
      "    |_embedding ->  0.363036 seconds\n",
      "    |_embedding ->  0.270307 seconds\n",
      "    |_embedding ->  0.189093 seconds\n",
      "    |_embedding ->  0.34064 seconds\n",
      "    |_embedding ->  0.295589 seconds\n",
      "    |_embedding ->  0.46581 seconds\n",
      "    |_embedding ->  0.211467 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# build index and query engine\n",
    "vector_query_engine = VectorStoreIndex(\n",
    "    nodes, use_async=False, service_context=service_context\n",
    ").as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup base query engine as tool\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=vector_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"job_descriptions\", description=\"Useful for answering questions about jobs\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 sub questions.\n",
      "\u001b[36;1m\u001b[1;3m[job_descriptions] Q: What are the key responsibilities of a data science job?\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[job_descriptions] Q: What are the required qualifications for a data science job?\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m[job_descriptions] Q: What are the common skills needed for a data science job?\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m[job_descriptions] Q: What are the typical salary ranges for data science jobs?\n",
      "\u001b[0m\u001b[31;1m\u001b[1;3m[job_descriptions] Q: What are the common job titles for data science roles?\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=37 request_id=c0b3276ae43eec602c65a4a5aeccbdee response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=37 request_id=c0b3276ae43eec602c65a4a5aeccbdee response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=37 request_id=c0b3276ae43eec602c65a4a5aeccbdee response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=71 request_id=49643f4a9202e50fb002c929c968b1aa response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=71 request_id=49643f4a9202e50fb002c929c968b1aa response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=71 request_id=49643f4a9202e50fb002c929c968b1aa response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=42 request_id=a939f4a8f4e7fbe71b17e966cc5e97e6 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=42 request_id=a939f4a8f4e7fbe71b17e966cc5e97e6 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=42 request_id=a939f4a8f4e7fbe71b17e966cc5e97e6 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=45 request_id=565c282008246efc81fb693f02ac93e6 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=45 request_id=565c282008246efc81fb693f02ac93e6 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=45 request_id=565c282008246efc81fb693f02ac93e6 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=ed61814e264ee5fc234c84e87483b233 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=ed61814e264ee5fc234c84e87483b233 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=18 request_id=ed61814e264ee5fc234c84e87483b233 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1507 request_id=bd367cfc6cc7666ff51d5fc9178a493f response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1507 request_id=bd367cfc6cc7666ff51d5fc9178a493f response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1507 request_id=bd367cfc6cc7666ff51d5fc9178a493f response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2463 request_id=6fe567f58ae930153d6a5dae275e8539 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2463 request_id=6fe567f58ae930153d6a5dae275e8539 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2463 request_id=6fe567f58ae930153d6a5dae275e8539 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1443 request_id=f2c7f010d8fb758ca6ad62df43127d82 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1443 request_id=f2c7f010d8fb758ca6ad62df43127d82 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1443 request_id=f2c7f010d8fb758ca6ad62df43127d82 response_code=200\n",
      "\u001b[31;1m\u001b[1;3m[job_descriptions] A: Refined Answer: The common job titles for data science roles mentioned in the context information are:\n",
      "\n",
      "1. Manager Data Science\n",
      "2. Data Scientists\n",
      "3. Data Scientist\n",
      "4. Data Scientist\n",
      "5. Data Scientist\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5136 request_id=7c6e4a0263faed66f5d1be3a688b4206 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5136 request_id=7c6e4a0263faed66f5d1be3a688b4206 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5136 request_id=7c6e4a0263faed66f5d1be3a688b4206 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6756 request_id=b5d36670d8ac45bbe9b786c37f1f8008 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6756 request_id=b5d36670d8ac45bbe9b786c37f1f8008 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6756 request_id=b5d36670d8ac45bbe9b786c37f1f8008 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4412 request_id=d081dca3ce3da47d1bed74e370b0aa4b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4412 request_id=d081dca3ce3da47d1bed74e370b0aa4b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4412 request_id=d081dca3ce3da47d1bed74e370b0aa4b response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6840 request_id=6e8d6e460891f83b510a74fa0ba6329a response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6840 request_id=6e8d6e460891f83b510a74fa0ba6329a response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6840 request_id=6e8d6e460891f83b510a74fa0ba6329a response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4606 request_id=6c08e30bfbd58281829bd4fd19b86efe response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4606 request_id=6c08e30bfbd58281829bd4fd19b86efe response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4606 request_id=6c08e30bfbd58281829bd4fd19b86efe response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4950 request_id=e00d1204960ce5717ab6fb08703e48f0 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4950 request_id=e00d1204960ce5717ab6fb08703e48f0 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4950 request_id=e00d1204960ce5717ab6fb08703e48f0 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4428 request_id=d659a609b6f6dace6e2ac8d3c48a0544 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4428 request_id=d659a609b6f6dace6e2ac8d3c48a0544 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4428 request_id=d659a609b6f6dace6e2ac8d3c48a0544 response_code=200\n",
      "\u001b[36;1m\u001b[1;3m[job_descriptions] A: The key responsibilities of a data science job at DeepScribe include gathering and analyzing data for capacity forecasts, experiment results, and optimization of demand profiles. This involves applying operations research and statistical models to solve core challenges and drive data-driven decisions related to human-in-the-loop Operations, Revenue Operations, and Product Operations. Additionally, the Data Scientist will build data infrastructure to measure individual user service level requirements, develop systems to intelligently route resources, and develop models to measure growth and absorption of human in the loop operations. They will also forecast capacity needs, ensure team members fulfill scheduled shifts, analyze product data to identify problems and ideate product features, and contribute to margin improvement and experimental efforts. Effective communication and collaboration with stakeholders and engineering teams is also essential in this role.\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9646 request_id=9469035a2bf00d01836b202d34051108 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9646 request_id=9469035a2bf00d01836b202d34051108 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9646 request_id=9469035a2bf00d01836b202d34051108 response_code=200\n",
      "\u001b[38;5;200m\u001b[1;3m[job_descriptions] A: The common skills needed for a data science job include:\n",
      "\n",
      "1. Programming Skills: Knowledge of statistical programming languages like R, Python, and database query languages like SQL, Hive, Pig. Familiarity with Scala, Java, or C++ is an added advantage.\n",
      "\n",
      "2. Statistics: Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.\n",
      "\n",
      "3. Machine Learning: Good knowledge of machine learning methods like k-Nearest Neighbors, Naive Bayes, SVM, Decision Forests.\n",
      "\n",
      "4. Strong Math Skills: Understanding the fundamentals of Multivariable Calculus and Linear Algebra.\n",
      "\n",
      "5. Data Wrangling: Proficiency in handling imperfections in data.\n",
      "\n",
      "6. Data Visualization: Experience with data visualization tools like matplotlib, ggplot, d3.js, Tableau.\n",
      "\n",
      "7. Excellent Communication Skills: Ability to describe findings to a technical and non-technical audience.\n",
      "\n",
      "8. Strong Software Engineering Background.\n",
      "\n",
      "9. Problem-solving aptitude.\n",
      "\n",
      "10. Analytical mind and great business sense.\n",
      "\n",
      "11. Degree in Computer Science, Engineering, or relevant field is preferred.\n",
      "\n",
      "In addition to these skills, the specific job postings provided additional context and requirements for data science roles. These include experience in data mining, operations research, data collection, and trading/investing. Knowledge of specific tools and frameworks such as Hadoop, Tableau, and business intelligence tools is also mentioned. The ability to work with large datasets, perform data analysis, and design and build data transformations are highlighted in the job descriptions as well.\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12294 request_id=962e97cbb2960a129486081a8f4cc029 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12294 request_id=962e97cbb2960a129486081a8f4cc029 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12294 request_id=962e97cbb2960a129486081a8f4cc029 response_code=200\n",
      "\u001b[32;1m\u001b[1;3m[job_descriptions] A: Based on the additional context provided, here are the refined typical salary ranges for data science jobs:\n",
      "\n",
      "- Data Scientist at Mercury:\n",
      "  - San Francisco or New York City: $145,000 - $175,000\n",
      "  - Outside of San Francisco or New York City (US): $135,000 - $150,000\n",
      "  - Canada: CAD 150,000 - CAD 180,000\n",
      "\n",
      "- Data Scientist (AI/ML, AWS) at DSMH LLC:\n",
      "  - Contract position: $60.00 - $65.00 per hour\n",
      "\n",
      "- Data Scientist at Narvee Technologies pvt ltd:\n",
      "  - Contract position: $50.00 - $55.00 per hour\n",
      "\n",
      "- Sr. Manager Data Science & Analytics at 3Q/DEPT:\n",
      "  - Anticipated salary range for New York: $140,000 - $150,000 (other factors may affect the final salary)\n",
      "\n",
      "- Jr. Data Scientist at Talentheed Inc:\n",
      "  - Anticipated salary range: $140,000 - $150,000 for individuals assigned and/or hired to work in New York (other factors may affect the final salary)\n",
      "\n",
      "- Azure Data Engineer at Agiles Enterprise:\n",
      "  - Salary range: $84,107.15 - $190,640.87 per year\n",
      "\n",
      "- Entry Level Data Scientist at I28 Technologies:\n",
      "  - Salary range: $65,000.00 - $70,000.00 per year\n",
      "\n",
      "- Data Scientist at COMTEC INFORMATION SYSTEMS:\n",
      "  - Salary range: $60.00 - $62.50 per hour\n",
      "\n",
      "- Data Scientist at Okaya Infocom:\n",
      "  - Salary range: $150,000.00 - $160,000.00 per year\n",
      "\n",
      "- Data Engineer at Rangam Consultants Inc.:\n",
      "  - Hourly rate: $60.00 - $70.00 per hour\n",
      "\n",
      "Please note that these salary ranges are based on the provided context and may vary depending on factors such as location, experience, and specific circumstances surrounding the final candidate.\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7745 request_id=61df6fda9a8b434a5b91c897255df8a3 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7745 request_id=61df6fda9a8b434a5b91c897255df8a3 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7745 request_id=61df6fda9a8b434a5b91c897255df8a3 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7207 request_id=feeb371c56f8c5faaa6f1d66838a8d20 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7207 request_id=feeb371c56f8c5faaa6f1d66838a8d20 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7207 request_id=feeb371c56f8c5faaa6f1d66838a8d20 response_code=200\n",
      "\u001b[33;1m\u001b[1;3m[job_descriptions] A: Based on the new context, the required qualifications for a data science job are as follows:\n",
      "\n",
      "- US Citizenship is required, and an active Secret clearance is highly desirable.\n",
      "- 5 years of Fraud Analytics experience is a must.\n",
      "- 5 or more years of hands-on experience developing analytic rules and models using leading edge fraud analytic tools and best practices.\n",
      "- 5 or more years of hand-on experience in programming in SAS (preferable), or any statistical software packages.\n",
      "- 5 or more years of hands-on experience of data management and advanced analytic techniques.\n",
      "- 5 or more years of hands-on experience proactively using data sciences to identify auditable controls that will detect and prevent fraud, waste, abuse, and mismanagement.\n",
      "- 5 or more years of hands-on experience coding rules and models using open-source programming techniques and tools.\n",
      "- Must have strong oral and written skills.\n",
      "- Must have experience working in team environments as well as independently.\n",
      "- Must have experience and knowledge of database structures and data organization.\n",
      "\n",
      "Please note that these qualifications are specific to the job posting provided and may not apply to all data science jobs. It's always recommended to carefully review the qualifications listed in each job posting to determine the specific requirements for that position.\n",
      "\u001b[0m**********\n",
      "Trace: query\n",
      "    |_query ->  43.238563 seconds\n",
      "      |_sub_question ->  19.322275 seconds\n",
      "        |_query ->  19.321276 seconds\n",
      "          |_retrieve ->  0.896568 seconds\n",
      "            |_embedding ->  0.620021 seconds\n",
      "          |_synthesize ->  18.424708 seconds\n",
      "            |_llm ->  4.123988 seconds\n",
      "            |_llm ->  4.612837 seconds\n",
      "            |_llm ->  4.770674 seconds\n",
      "            |_llm ->  4.580944 seconds\n",
      "      |_sub_question ->  30.678153 seconds\n",
      "        |_query ->  30.678153 seconds\n",
      "          |_retrieve ->  1.404615 seconds\n",
      "            |_embedding ->  1.130361 seconds\n",
      "          |_synthesize ->  29.273538 seconds\n",
      "            |_llm ->  8.452578 seconds\n",
      "            |_llm ->  5.126188 seconds\n",
      "            |_llm ->  7.960845 seconds\n",
      "            |_llm ->  7.371907 seconds\n",
      "      |_sub_question ->  19.498992 seconds\n",
      "        |_query ->  19.498992 seconds\n",
      "          |_retrieve ->  0.461199 seconds\n",
      "            |_embedding ->  0.184413 seconds\n",
      "          |_synthesize ->  19.037793 seconds\n",
      "            |_llm ->  9.083723 seconds\n",
      "            |_llm ->  9.784159 seconds\n",
      "      |_sub_question ->  20.389234 seconds\n",
      "        |_query ->  20.389234 seconds\n",
      "          |_retrieve ->  2.398855 seconds\n",
      "            |_embedding ->  2.118551 seconds\n",
      "          |_synthesize ->  17.990379 seconds\n",
      "            |_llm ->  5.319968 seconds\n",
      "            |_llm ->  12.435819 seconds\n",
      "      |_sub_question ->  5.970478 seconds\n",
      "        |_query ->  5.970478 seconds\n",
      "          |_retrieve ->  1.924847 seconds\n",
      "            |_embedding ->  1.649836 seconds\n",
      "          |_synthesize ->  4.045631 seconds\n",
      "            |_llm ->  2.178605 seconds\n",
      "            |_llm ->  1.620632 seconds\n",
      "      |_synthesize ->  7.540927 seconds\n",
      "        |_llm ->  7.486503 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Review 10 data science jobs and summarize their similarities and differences?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the context information provided, here is a summary of the similarities and differences among the 10 data science jobs:\n",
       "\n",
       "Similarities:\n",
       "- All 10 jobs require strong skills in programming, statistics, machine learning, and data wrangling.\n",
       "- They all emphasize the importance of good communication skills and the ability to present findings to both technical and non-technical audiences.\n",
       "- A degree in Computer Science, Engineering, or a relevant field is preferred for all positions.\n",
       "- The jobs require experience in data analysis and working with large datasets.\n",
       "- They all mention the need for problem-solving aptitude and an analytical mind.\n",
       "\n",
       "Differences:\n",
       "- The salary ranges vary significantly across the different jobs, with some offering hourly rates and others offering annual salaries.\n",
       "- Some jobs require specific experience in fraud analytics, while others mention experience in areas like operations research, data mining, and trading/investing.\n",
       "- The required qualifications for each job differ, with some jobs requiring US citizenship and an active Secret clearance, while others do not mention these requirements.\n",
       "- The job titles vary, with positions like Data Scientist, Manager Data Science, and Azure Data Engineer being mentioned.\n",
       "\n",
       "Overall, while there are similarities in the skills and qualifications required for these data science jobs, there are also notable differences in terms of specific experience, qualifications, and salary ranges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assist with the tuning and performance of the database environment, determining optimum values for database attributes.\n"
     ]
    }
   ],
   "source": [
    "example_job = df.Description.sample(1, random_state=8).tolist()\n",
    "print(example_job[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_prompt = \"\"\"The following is job description we are interested in.\n",
    "\n",
    "\"Assist with the tuning and performance of the database environment, determining optimum values for database attributes.\"\n",
    "\n",
    "Based on this job description, please do 2 things: \n",
    "(1) find similar job descriptions\n",
    "(2) compare and contrast the similar jobs with the description from our job of interest\n",
    "\n",
    "Helpful Comparison:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 sub questions.\n",
      "\u001b[36;1m\u001b[1;3m[job_descriptions] Q: Find similar job descriptions\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[job_descriptions] Q: Compare and contrast similar jobs with the description from our job of interest\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=7c8c1fa732247b32774ac9a4b583ebcf response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=7c8c1fa732247b32774ac9a4b583ebcf response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=26 request_id=7c8c1fa732247b32774ac9a4b583ebcf response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=59b16a906595391808a6b813978c0683 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=59b16a906595391808a6b813978c0683 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=21 request_id=59b16a906595391808a6b813978c0683 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6638 request_id=ddf06dbc9f28d35bbd5587f5b8f9f85d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6638 request_id=ddf06dbc9f28d35bbd5587f5b8f9f85d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6638 request_id=ddf06dbc9f28d35bbd5587f5b8f9f85d response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9100 request_id=74b47a517e770d939f56152d7d7fe4e5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9100 request_id=74b47a517e770d939f56152d7d7fe4e5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=9100 request_id=74b47a517e770d939f56152d7d7fe4e5 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1554 request_id=ae5f8d541bd10d399f070686b209bc3c response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1554 request_id=ae5f8d541bd10d399f070686b209bc3c response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1554 request_id=ae5f8d541bd10d399f070686b209bc3c response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5541 request_id=56fbad151e7ecc52e0a96594587148a3 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5541 request_id=56fbad151e7ecc52e0a96594587148a3 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5541 request_id=56fbad151e7ecc52e0a96594587148a3 response_code=200\n",
      "\u001b[36;1m\u001b[1;3m[job_descriptions] A: Based on the new context provided, the job descriptions that are similar to the \"Data Engineer\" role are:\n",
      "\n",
      "1. Data Scientist at The Josef Group Inc.: This role involves data mining, preprocessing, and analysis, as well as developing prediction systems and machine learning algorithms. It requires programming skills in languages like R and Python, proficiency in statistics, and strong math skills.\n",
      "\n",
      "2. SQL Database Administrator at Saxon Global: This role involves programming in SQL, database administration, and query tuning. It requires expertise in SQL scripting and modifications, as well as experience with T-SQL stored procedures.\n",
      "\n",
      "3. IT Business Intelligence Developer at Ballad Health: This role involves developing and maintaining business intelligence solutions, defining reporting requirements, and performing data analysis. It requires experience in SQL queries, data visualization techniques, and IT/systems analysis.\n",
      "\n",
      "These job descriptions share similarities with the Data Engineer role in terms of working with data, performing analysis, and utilizing SQL skills.\n",
      "\u001b[0mINFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1434 request_id=a1235b38c4381a68405e3058764776b8 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1434 request_id=a1235b38c4381a68405e3058764776b8 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1434 request_id=a1235b38c4381a68405e3058764776b8 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1599 request_id=f1f4133816b94ceb9bd801ee5a4c989b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1599 request_id=f1f4133816b94ceb9bd801ee5a4c989b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1599 request_id=f1f4133816b94ceb9bd801ee5a4c989b response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1388 request_id=2ec3bb167ff648e7b2ce2f095b1bd07c response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1388 request_id=2ec3bb167ff648e7b2ce2f095b1bd07c response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1388 request_id=2ec3bb167ff648e7b2ce2f095b1bd07c response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1606 request_id=9f66ea8cf71c7d9ddbf33f8e98f21d9d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1606 request_id=9f66ea8cf71c7d9ddbf33f8e98f21d9d response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1606 request_id=9f66ea8cf71c7d9ddbf33f8e98f21d9d response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1407 request_id=4aca43ac60b8ad4b76dc496f18a4db9a response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1407 request_id=4aca43ac60b8ad4b76dc496f18a4db9a response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1407 request_id=4aca43ac60b8ad4b76dc496f18a4db9a response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1609 request_id=611f78e5e9eb5ecc36df2ca1923b7880 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1609 request_id=611f78e5e9eb5ecc36df2ca1923b7880 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1609 request_id=611f78e5e9eb5ecc36df2ca1923b7880 response_code=200\n",
      "\u001b[33;1m\u001b[1;3m[job_descriptions] A: Based on the new context provided, the original answer remains relevant and accurate. The comparison and contrast between the job of interest and the other two positions are still valid. Therefore, there is no need to refine the original answer.\n",
      "\u001b[0m**********\n",
      "Trace: query\n",
      "    |_query ->  33.044875 seconds\n",
      "      |_sub_question ->  14.081838 seconds\n",
      "        |_query ->  14.081838 seconds\n",
      "          |_retrieve ->  1.146781 seconds\n",
      "            |_embedding ->  0.87178 seconds\n",
      "          |_synthesize ->  12.934058 seconds\n",
      "            |_llm ->  7.022767 seconds\n",
      "            |_llm ->  5.719762 seconds\n",
      "      |_sub_question ->  23.372302 seconds\n",
      "        |_query ->  23.371329 seconds\n",
      "          |_retrieve ->  0.429292 seconds\n",
      "            |_embedding ->  0.150966 seconds\n",
      "          |_synthesize ->  22.942037 seconds\n",
      "            |_llm ->  9.924222 seconds\n",
      "            |_llm ->  1.931119 seconds\n",
      "            |_llm ->  1.605452 seconds\n",
      "            |_llm ->  1.966432 seconds\n",
      "            |_llm ->  1.53964 seconds\n",
      "            |_llm ->  1.807694 seconds\n",
      "            |_llm ->  1.581954 seconds\n",
      "            |_llm ->  1.797367 seconds\n",
      "      |_synthesize ->  7.427998 seconds\n",
      "        |_llm ->  7.414511 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    comparison_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "(1) Similar job descriptions:\n",
       "1. Database Administrator at ABC Company: This role involves managing and maintaining the performance, integrity, and security of the company's databases. It includes tasks such as database tuning, optimizing queries, and determining optimal database configurations.\n",
       "\n",
       "2. Database Performance Engineer at XYZ Corporation: This role focuses specifically on optimizing database performance. It involves analyzing database performance metrics, identifying bottlenecks, and implementing performance tuning strategies to improve database efficiency.\n",
       "\n",
       "(2) Comparison and contrast:\n",
       "The job description provided is similar to both the Database Administrator and Database Performance Engineer roles in terms of focusing on database tuning and performance optimization. However, there are some differences between the roles:\n",
       "\n",
       "- The job of interest seems to have a broader scope, as it includes assisting with tuning and performance of the entire database environment, whereas the Database Administrator role may involve additional responsibilities such as database security and integrity maintenance.\n",
       "\n",
       "- The Database Performance Engineer role, on the other hand, is more specialized and focused solely on optimizing database performance. This role may involve in-depth analysis of performance metrics and implementing specific strategies to improve efficiency.\n",
       "\n",
       "Overall, while all three roles involve database tuning and performance optimization, the job of interest appears to have a broader scope, encompassing various aspects of the database environment, while the other two roles may have more specific focuses within the realm of database performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.callbacks import get_openai_callback\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics by Cluster Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 has 0    281\n",
      "Name: 4, dtype: int64 messages\n",
      "['Familiarity with data visualization tools.\\nComfortable pulling and manipulating data using SQL.\\nParticipates in and oversees the Data Science team in analyzing…'\n",
      " \"This team's key partners include other product teams, finance, data science, and other teams within data engineering.\"\n",
      " 'A storyteller, be able to make sense of data and extrapolate meaningful and actionable insights.\\nUse website data to create compelling stories and succinct…'\n",
      " 'Set data standards and oversee stewardship, ensuring that all products and services have data standards built in from the start.']\n",
      "\n",
      "\n",
      "3 has 0    274\n",
      "Name: 3, dtype: int64 messages\n",
      "['And methodology, and data visualization (PowerBI, Tableau, etc.).\\nSalary: * depending on relevant industry experience.\\nA Day In The Life of a Data Engineer I*.'\n",
      " 'A Master’s degree or higher in a relevant field such as computer science, data science, applied statistics, or a quantitative social science field or a bachelor…'\n",
      " 'We are looking for a data engineer who has passion for data integration technologies and comes with data warehousing background.'\n",
      " 'Define long term vision and roadmap for the data science/ML capabilities.\\n2+ years of management experience leading data scientists.']\n",
      "\n",
      "\n",
      "5 has 0    211\n",
      "Name: 5, dtype: int64 messages\n",
      "['Lead workshops, document business requirements.\\nMinimum 9 years of experience in converting functional requirements into technical specifications, and configure…'\n",
      " 'The BI Developer is responsible for all stages of the business intelligence cycle: understanding business objectives, collecting business requirements,…'\n",
      " 'Work with business users and other assigned team members to gather and document business requirements, analyze, design technical solutions.'\n",
      " 'Ability to perform detailed business analysis and design.\\nProduce Ad Hoc Reports to answer business questions quickly and thoroughly.']\n",
      "\n",
      "\n",
      "1 has 0    180\n",
      "Name: 1, dtype: int64 messages\n",
      "['Develop custom data models and algorithms to apply to data sets.\\nMachine Learning – good knowledge of machine learning methods like k-Nearest Neighbors, Naive…'\n",
      " 'Experience putting machine learning models into production.\\nHas strong fundamentals in machine learning and statistics evidenced by a track record of…'\n",
      " 'Experience working with machine learning algorithms to solve classification and clustering problems, perform information retrieval from unstructured and semi…'\n",
      " 'We have an immediate opening for a machine learning engineer with experience in object detection, deep learning, and modeling.\\nPython Flask: 1 year (Required).']\n",
      "\n",
      "\n",
      "0 has 0    146\n",
      "Name: 0, dtype: int64 messages\n",
      "['Backup and Recovery – Create, test and deploy database backup and recovery processes using vender utilities.'\n",
      " 'Perform database administration maintenance activities while maintaining high database system availability and reliability for business applications.'\n",
      " 'Identifying and resolving problems occurring in all database environments including performance related issues (i.e. database & SQL tuning).'\n",
      " 'Maintain Iris (the database system Epic runs on).\\nMaintain the files that allow for Epic client communication with the database.']\n",
      "\n",
      "\n",
      "2 has 0    108\n",
      "Name: 2, dtype: int64 messages\n",
      "['[redacted] Engineering is seeking a React Web Developer to bolster the data-driven design and user experience of our platform.'\n",
      " 'FC Project Manager II, Data Science Our Opportunity: Chewy is hiring a FC Project Manager II, Data Science for a technical role to support our North…'\n",
      " 'Work closely with internal and external team members to develop and build self-service capabilities, and automation, to enable our internal customers to move…'\n",
      " 'Responsibilities will include AEM headful component development and configuration in CRXDE.\\nYou will work with Lead Front End Developers on specification and…']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort clusters by their size, and create a new dataframe with the size and cluster number in sorted order. Maintain other columns\n",
    "size_and_cluster_number = pd.DataFrame(df.groupby(\"kmeans_label\").size().sort_values(ascending=False))\n",
    "\n",
    "# print out 10 messages from n cluster\n",
    "for cluster_number, size in size_and_cluster_number.iterrows():\n",
    "    print(f\"{cluster_number} has {size} messages\")\n",
    "    print(df[df.kmeans_label == cluster_number].sample(4).Description.values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">token_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3641</td>\n",
       "      <td>24.938356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4766</td>\n",
       "      <td>26.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3109</td>\n",
       "      <td>28.787037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7529</td>\n",
       "      <td>27.478102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7419</td>\n",
       "      <td>26.402135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5266</td>\n",
       "      <td>24.957346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token_count           \n",
       "                     sum       mean\n",
       "kmeans_label                       \n",
       "0                   3641  24.938356\n",
       "1                   4766  26.477778\n",
       "2                   3109  28.787037\n",
       "3                   7529  27.478102\n",
       "4                   7419  26.402135\n",
       "5                   5266  24.957346"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kmeans_label').agg({\n",
    "    'token_count': ['sum', 'mean']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample questions\n",
    "We can sample around 4k tokens worth of questions. To do this, we shuffle the questions in each cluster, then cut the first ~4k token chunk from each cluster. This should give us ~50% sample ratio on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 has 0    281\n",
      "Name: 4, dtype: int64 messages\n",
      "3 has 0    274\n",
      "Name: 3, dtype: int64 messages\n",
      "5 has 0    211\n",
      "Name: 5, dtype: int64 messages\n",
      "1 has 0    180\n",
      "Name: 1, dtype: int64 messages\n",
      "0 has 0    146\n",
      "Name: 0, dtype: int64 messages\n",
      "2 has 0    108\n",
      "Name: 2, dtype: int64 messages\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def create_doc(messages, max_tokens=3800):\n",
    "    #sample around 125 messages from the cluster\n",
    "    input_doc = '\\n\\n'.join(messages)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens, chunk_overlap=0, separator=\"\\n\\n\")\n",
    "    # Sanity check\n",
    "    split_texts = text_splitter.split_text(input_doc)\n",
    "    \n",
    "    return split_texts[0]\n",
    "\n",
    "\n",
    "# for clusters, create docs and save in list\n",
    "docs = []\n",
    "for cluster_number, size in size_and_cluster_number.iterrows():\n",
    "    print(f\"{cluster_number} has {size} messages\")\n",
    "    Description = df[df.kmeans_label == cluster_number].Description.values\n",
    "    doc = create_doc(Description)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "map_template_string = \"\"\"The following is a list of texts that have been clustered using K-Means.\n",
    "{questions}\n",
    "\n",
    "Based on this list of questions, please do 3 things: \n",
    "(1) Identify the main theme\n",
    "(2) Give a list of 3 to 5 main sub-themes\n",
    "(3) Give a representitive example text in each sub-theme\n",
    "(4) Estimate the proportion of questions that fall into each theme\n",
    "(5) Share observations on outliers, i.e. questions that do not seem to belong\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"questions\"], template=map_template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_map(input_doc):\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "   \n",
    "    return map_llm_chain.run(questions=input_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Single cluster test with GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_index.token_catcher import Usage\n",
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    gpt_35_test_result = run_map(docs[0])\n",
    "    print(cb)\n",
    "    print(gpt_35_test_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3880"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4 Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_results = []\n",
    "\n",
    "for input_doc in docs:\n",
    "    result=run_map(input_doc)\n",
    "    gpt4_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23889"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 281 messages: \n",
      "\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"We make data science workflows repeatable, scalable, and observable while reducing toil and increasing release velocity.\" These texts may require further analysis to determine their appropriate categorization.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 1 has 274 messages: \n",
      "\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   - Example Text: \"5+ years of relevant experience in report development, data science, business analytics, business intelligence, or comparable data engineering role, including…\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   - Example Text: \"Experience with traditional data warehouse data structures.\"\n",
      "   \n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   - Example Text: \"5+ years management experience building and leading data science teams.\"\n",
      "   \n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   - Example Text: \"Should have strong data analysis.\"\n",
      "   \n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   - Example Text: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience in data science and data engineering: 30%\n",
      "- Experience with specific tools and technologies: 20%\n",
      "- Experience in managing and leading data science teams: 10%\n",
      "- Experience with data analysis and data visualization: 20%\n",
      "- Experience with data pipelines and data integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are no clear outliers in this list of texts. All the texts are related to data science and data engineering experience, with varying levels of specificity in terms of tools, technologies, and management experience.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 2 has 211 messages: \n",
      "\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 3 has 180 messages: \n",
      "\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 4 has 146 messages: \n",
      "\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 5 has 108 messages: \n",
      "\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers in the list that do not seem to belong to any of the main themes. These include texts related to healthcare, government agencies, and education. These outliers make up approximately 10% of the questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "for i, result in enumerate(gpt4_results):\n",
    "\n",
    "    #print size of cluster\n",
    "    print(f\"Cluster {i} has {size_and_cluster_number.iloc[i].values[0]} messages: \\n\")\n",
    "\n",
    "    #print the summary\n",
    "    print(result)\n",
    "\n",
    "    #print separator\n",
    "    print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5-Turbo Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n",
      "Tokens Used: 3928\n",
      "\tPrompt Tokens: 3566\n",
      "\tCompletion Tokens: 362\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.006072999999999999\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   Example: \"10+ years of technical experience in a data science role or equivalent.\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   Example: \"Experience with traditional data warehouse data structures.\"\n",
      "\n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   Example: \"5+ years management experience building and leading data science teams.\"\n",
      "\n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   Example: \"Familiarity with data exploration and data visualization tools, like Tableau, Datorama, etc.\"\n",
      "\n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   Example: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience: 30%\n",
      "- Experience with tools and technologies: 20%\n",
      "- Managing and leading teams: 10%\n",
      "- Data analysis and visualization: 20%\n",
      "- Data pipelines and integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outliers in the list of texts that do not seem to belong to the main theme of data science and data engineering experience. These outliers include texts related to software development, business intelligence, and project management. These texts may have been included in the clustering process due to similarities in keywords or phrases, but they do not align with the main theme.\n",
      "Tokens Used: 7812\n",
      "\tPrompt Tokens: 7152\n",
      "\tCompletion Tokens: 660\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.012048\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "Tokens Used: 11622\n",
      "\tPrompt Tokens: 10691\n",
      "\tCompletion Tokens: 931\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.0178985\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "Tokens Used: 15431\n",
      "\tPrompt Tokens: 14247\n",
      "\tCompletion Tokens: 1184\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.023738500000000003\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "Tokens Used: 18945\n",
      "\tPrompt Tokens: 17473\n",
      "\tCompletion Tokens: 1472\n",
      "Successful Requests: 5\n",
      "Total Cost (USD): $0.029153500000000002\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example text: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example text: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 10% of questions\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example text: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example text: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example text: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers that do not seem to belong to any of the main themes. These include texts related to healthcare, payroll, public health, and bookkeeping. These outliers make up around 10% of the questions.\n"
     ]
    }
   ],
   "source": [
    "gpt35_results = []\n",
    "with get_openai_callback() as cb:\n",
    "    for input_doc in docs:\n",
    "        result=run_map(input_doc)\n",
    "        gpt35_results.append(result)\n",
    "        print(cb)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18945"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 281 messages: \n",
      "\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 1 has 274 messages: \n",
      "\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   Example: \"10+ years of technical experience in a data science role or equivalent.\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   Example: \"Experience with traditional data warehouse data structures.\"\n",
      "\n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   Example: \"5+ years management experience building and leading data science teams.\"\n",
      "\n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   Example: \"Familiarity with data exploration and data visualization tools, like Tableau, Datorama, etc.\"\n",
      "\n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   Example: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience: 30%\n",
      "- Experience with tools and technologies: 20%\n",
      "- Managing and leading teams: 10%\n",
      "- Data analysis and visualization: 20%\n",
      "- Data pipelines and integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outliers in the list of texts that do not seem to belong to the main theme of data science and data engineering experience. These outliers include texts related to software development, business intelligence, and project management. These texts may have been included in the clustering process due to similarities in keywords or phrases, but they do not align with the main theme.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 2 has 211 messages: \n",
      "\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 3 has 180 messages: \n",
      "\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 4 has 146 messages: \n",
      "\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 5 has 108 messages: \n",
      "\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example text: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example text: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 10% of questions\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example text: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example text: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example text: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers that do not seem to belong to any of the main themes. These include texts related to healthcare, payroll, public health, and bookkeeping. These outliers make up around 10% of the questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "for i, result in enumerate(gpt35_results):\n",
    "\n",
    "    #print size of cluster\n",
    "    print(f\"Cluster {i} has {size_and_cluster_number.iloc[i].values[0]} messages: \\n\")\n",
    "\n",
    "    #print the summary\n",
    "    print(result)\n",
    "\n",
    "    #print separator\n",
    "    print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send all cases through Map Reduce chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "input_doc = '\\n\\n'.join(docs)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=4000,chunk_overlap=0,separator=\"\\n\\n\")\n",
    "# Sanity check\n",
    "len(text_splitter.split_text(input_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_template_string = \"\"\"The following is a list of texts that have been clustered using K-Means\n",
    "{questions}\n",
    "\n",
    "Based on this list of texts, please do 4 things: \n",
    "(1) identify the main themes \n",
    "(2) give a represntitive example question in each theme\n",
    "(3) estimate the proportion of questions that fall into each theme\n",
    "(4) share observations on outliers, i.e. questions that do not seem to belong\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_template_string = template = \"\"\"The following is a list of summaries for questions entered into a Q+A system:\n",
    "{question_summaries}\n",
    "\n",
    "Take these and distill it into a final, consolidated list with: \n",
    "(1) the main question themes \n",
    "(2) two represntitive example questions in each theme\n",
    "(3) estimate the proportion of questions that fall into each theme\n",
    "(4) a summary of outliers\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"questions\"], template=map_template_string)\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"question_summaries\"], template=reduce_template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import (\n",
    "                StuffDocumentsChain,\n",
    "                LLMChain,\n",
    "                ReduceDocumentsChain,\n",
    "                MapReduceDocumentsChain,\n",
    "            )\n",
    "\n",
    "\n",
    "def run_map_reduce(input_doc, model, MAP_PROMPT, REDUCE_PROMPT):\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=model, temperature=0)\n",
    "    map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "\n",
    "    llm = ChatOpenAI(model_name=model, temperature=0)\n",
    "    reduce_llm_chain = LLMChain(llm=llm, prompt=REDUCE_PROMPT)\n",
    "\n",
    "    # Takes a list of documents and combines them into a single string\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "            llm_chain=reduce_llm_chain,\n",
    "            document_variable_name=\"question_summaries\")\n",
    "    \n",
    "    # Combines and iteravely reduces the mapped documents \n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `combine_documents_chain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=4000)\n",
    "\n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    combine_documents = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_llm_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"questions\",\n",
    "        # Return the results of the map steps in the output\n",
    "        ### Bug: this currently does not work ###\n",
    "        return_intermediate_steps=False)\n",
    "        \n",
    "    # Define Map=Reduce\n",
    "    map_reduce = MapReduceChain(\n",
    "        # Chain to combine documents\n",
    "        combine_documents_chain=combine_documents,\n",
    "        # Splitter to use for initial split\n",
    "        text_splitter=text_splitter)\n",
    "    \n",
    "    return map_reduce.run(input_text=input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117588"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20346"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 5059\n",
      "\tPrompt Tokens: 4146\n",
      "\tCompletion Tokens: 913\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.17915999999999999\n",
      "\n",
      "Cluster: 0:\n",
      "(1) Main Question Themes:\n",
      "   - Data Science Strategy and Management\n",
      "   - Data Analysis and Insights\n",
      "   - Data Engineering and Infrastructure\n",
      "   - Collaboration and Teamwork\n",
      "   - Data Governance and Security\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Data Science Strategy and Management: \n",
      "     1. \"How do you define and execute a data science strategy that ensures our organization's success?\"\n",
      "     2. \"What are the key elements in setting up a successful data science workflow?\"\n",
      "   - Data Analysis and Insights: \n",
      "     1. \"How do you analyze product data to identify problems and ideate product features?\"\n",
      "     2. \"What methods do you use to turn raw data into actionable insights?\"\n",
      "   - Data Engineering and Infrastructure: \n",
      "     1. \"How do you manage and scale data pipelines from internal and external data sources?\"\n",
      "     2. \"What are the best practices for ensuring data quality in data extraction and transformation processes?\"\n",
      "   - Collaboration and Teamwork: \n",
      "     1. \"How do you collaborate with software developers, other data engineers, and database managers to automate repeatable data tasks?\"\n",
      "     2. \"What strategies do you use to ensure effective collaboration between data science teams and business users?\"\n",
      "   - Data Governance and Security: \n",
      "     1. \"How do you incorporate core data management competencies including data governance, data security, and data quality?\"\n",
      "     2. \"What measures do you take to ensure data integrity and compliance with data protection regulations?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Data Science Strategy and Management: 30%\n",
      "   - Data Analysis and Insights: 25%\n",
      "   - Data Engineering and Infrastructure: 20%\n",
      "   - Collaboration and Teamwork: 15%\n",
      "   - Data Governance and Security: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions focus on specific sectors or applications of data science, such as healthcare or marketing, which do not fit neatly into the main themes.\n",
      "   - Some questions mention specific locations or eligibility requirements, which are not related to the main themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 9853\n",
      "\tPrompt Tokens: 8175\n",
      "\tCompletion Tokens: 1678\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.34592999999999996\n",
      "\n",
      "Cluster: 1:\n",
      "(1) Main Question Themes:\n",
      "   - Data Science Experience\n",
      "   - Data Engineering Skills\n",
      "   - Management Experience\n",
      "   - Education\n",
      "   - Project Experience\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Data Science Experience: \n",
      "     1. \"How many years of experience do you have in a data science role?\"\n",
      "     2. \"Can you describe your experience in data analytics?\"\n",
      "   - Data Engineering Skills: \n",
      "     1. \"Do you have experience working with SQL, Hadoop, Spark, or AWS?\"\n",
      "     2. \"Can you list the data engineering technologies you are proficient in?\"\n",
      "   - Management Experience: \n",
      "     1. \"Have you ever managed or led a data science or data engineering team?\"\n",
      "     2. \"Can you describe your experience in leading data projects?\"\n",
      "   - Education: \n",
      "     1. \"What is your highest level of education in a field related to data science or data engineering?\"\n",
      "     2. \"Do you hold any degrees or certifications in data science or data engineering?\"\n",
      "   - Project Experience: \n",
      "     1. \"Can you describe a project where you developed a data pipeline or performed data analysis?\"\n",
      "     2. \"What types of data integration projects have you worked on?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Data Science Experience: 40%\n",
      "   - Data Engineering Skills: 30%\n",
      "   - Management Experience: 10%\n",
      "   - Education: 10%\n",
      "   - Project Experience: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific industries or business domains, such as finance or retail, which do not fit neatly into the main themes.\n",
      "   - Some questions mention specific tools or technologies that are not commonly used in data science or data engineering, such as Confluent Kafka or Oracle 12C.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 14877\n",
      "\tPrompt Tokens: 12285\n",
      "\tCompletion Tokens: 2592\n",
      "Successful Requests: 6\n",
      "Total Cost (USD): $0.5240699999999999\n",
      "\n",
      "Cluster: 2:\n",
      "(1) Main Question Themes:\n",
      "   - Business Intelligence Development\n",
      "   - Business Analysis\n",
      "   - Project Management\n",
      "   - Data Analysis\n",
      "   - Client/Stakeholder Interaction\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Business Intelligence Development: \n",
      "     1. \"What experience do you have in creating analytical reports/dashboards to monitor data issues and business processes?\"\n",
      "     2. \"Can you describe your experience in maintaining business intelligence solutions, reports, dashboards, and scorecards?\"\n",
      "   - Business Analysis: \n",
      "     1. \"Can you provide an example of a time when you had to define configuration specifications and business analysis requirements for a project?\"\n",
      "     2. \"How do you go about translating business needs into technical requirements?\"\n",
      "   - Project Management: \n",
      "     1. \"What experience do you have in leading the process for identifying and gathering appropriate business requirements to create necessary solutions that satisfy business needs?\"\n",
      "     2. \"Can you describe a project where you ensured the outcomes met the business needs?\"\n",
      "   - Data Analysis: \n",
      "     1. \"Can you describe a time when you had to analyze data to draw business-relevant conclusions and provide data solutions?\"\n",
      "     2. \"How do you go about monitoring data issues in your role?\"\n",
      "   - Client/Stakeholder Interaction: \n",
      "     1. \"Can you provide an example of a time when you had to work with business users and other team members to gather and document business requirements?\"\n",
      "     2. \"How do you ensure you understand the business needs of your clients or stakeholders?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Business Intelligence Development: 30%\n",
      "   - Business Analysis: 25%\n",
      "   - Project Management: 20%\n",
      "   - Data Analysis: 15%\n",
      "   - Client/Stakeholder Interaction: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions focus on specific software or tools such as SAP Business Objects suite, Power BI, Jira, and Informatica mappings/workflows, which are more specific technical skills rather than overarching themes.\n",
      "   - Some questions mention experience requirements, which are not thematic but rather specific job requirements.\n",
      "   - Some questions mention remote work and flexibility, which are more about work conditions rather than job roles or responsibilities.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 19897\n",
      "\tPrompt Tokens: 16317\n",
      "\tCompletion Tokens: 3580\n",
      "Successful Requests: 8\n",
      "Total Cost (USD): $0.70431\n",
      "\n",
      "Cluster: 3:\n",
      "(1) Main Question Themes:\n",
      "   - Machine Learning Model Development and Deployment\n",
      "   - Data Science and Analytics\n",
      "   - AI and Deep Learning Techniques\n",
      "   - Tools and Frameworks for Machine Learning\n",
      "   - Experience and Expertise in Machine Learning\n",
      "   - Research and Innovation in Machine Learning\n",
      "\n",
      "(2) Two Representative Example Questions in Each Theme:\n",
      "   - Machine Learning Model Development and Deployment: \n",
      "     1. \"What experience do you have in developing and deploying machine learning models for ad recommendation?\"\n",
      "     2. \"Can you explain your process for developing and deploying a machine learning model?\"\n",
      "   - Data Science and Analytics: \n",
      "     1. \"Can you provide examples of your proficiency with data mining and machine learning?\"\n",
      "     2. \"How have you used data science and analytics in your previous roles?\"\n",
      "   - AI and Deep Learning Techniques: \n",
      "     1. \"What is your understanding of various advanced analytical and machine learning methods?\"\n",
      "     2. \"Can you explain how you have applied AI and deep learning techniques in your work?\"\n",
      "   - Tools and Frameworks for Machine Learning: \n",
      "     1. \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\"\n",
      "     2. \"What tools and frameworks do you typically use for machine learning projects?\"\n",
      "   - Experience and Expertise in Machine Learning: \n",
      "     1. \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\"\n",
      "     2. \"What is your level of expertise in machine learning?\"\n",
      "   - Research and Innovation in Machine Learning: \n",
      "     1. \"Have you published any work at major machine learning conferences or in major scientific journals?\"\n",
      "     2. \"Can you discuss any innovative approaches you've taken in your machine learning research?\"\n",
      "\n",
      "(3) Estimated Proportion of Questions That Fall into Each Theme:\n",
      "   - Machine Learning Model Development and Deployment: 30%\n",
      "   - Data Science and Analytics: 20%\n",
      "   - AI and Deep Learning Techniques: 15%\n",
      "   - Tools and Frameworks for Machine Learning: 15%\n",
      "   - Experience and Expertise in Machine Learning: 10%\n",
      "   - Research and Innovation in Machine Learning: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific industries or applications, such as \"computer vision\", \"natural language processing\", or \"ad recommendation\", which are not common across all questions.\n",
      "   - Some questions mention specific tools or languages, such as \"Python\", \"TensorFlow\", or \"SQL\", which are not common across all questions.\n",
      "   - Some questions mention specific experience requirements, such as \"Python Flask: 1 year (Required)\" or \"Machine learning: 1 year (Preferred)\", which are not common across all questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 24874\n",
      "\tPrompt Tokens: 20338\n",
      "\tCompletion Tokens: 4536\n",
      "Successful Requests: 10\n",
      "Total Cost (USD): $0.8823\n",
      "\n",
      "Cluster: 4:\n",
      "(1) Main Question Themes:\n",
      "   - Database Administration and Maintenance\n",
      "   - Database Security\n",
      "   - Database Performance Optimization\n",
      "   - Database Troubleshooting\n",
      "   - Database Backup and Recovery\n",
      "   - Database Design and Development\n",
      "   - Database Software and Tools\n",
      "   - Database Experience and Skills\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Database Administration and Maintenance: \n",
      "     1. \"What is your experience in database administration and maintenance?\"\n",
      "     2. \"How do you manage routine database maintenance tasks?\"\n",
      "   - Database Security: \n",
      "     1. \"How do you ensure the security of a database?\"\n",
      "     2. \"What measures do you take to prevent unauthorized access to databases?\"\n",
      "   - Database Performance Optimization: \n",
      "     1. \"What strategies do you use to optimize database performance?\"\n",
      "     2. \"How do you handle performance issues in a database?\"\n",
      "   - Database Troubleshooting: \n",
      "     1. \"Can you describe a time when you had to troubleshoot a complex database issue?\"\n",
      "     2. \"What steps do you take to diagnose and resolve database problems?\"\n",
      "   - Database Backup and Recovery: \n",
      "     1. \"What is your approach to database backup and recovery?\"\n",
      "     2. \"How do you plan and execute a database recovery strategy?\"\n",
      "   - Database Design and Development: \n",
      "     1. \"Can you describe a database you have designed and developed?\"\n",
      "     2. \"What principles do you follow when designing a new database?\"\n",
      "   - Database Software and Tools: \n",
      "     1. \"What database software and tools are you proficient in?\"\n",
      "     2. \"How do you use database management tools to improve efficiency?\"\n",
      "   - Database Experience and Skills: \n",
      "     1. \"What is your experience and skill level with SQL, Oracle, and other databases?\"\n",
      "     2. \"Can you share your experience with database programming languages?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Database Administration and Maintenance: 25%\n",
      "   - Database Security: 10%\n",
      "   - Database Performance Optimization: 15%\n",
      "   - Database Troubleshooting: 10%\n",
      "   - Database Backup and Recovery: 10%\n",
      "   - Database Design and Development: 15%\n",
      "   - Database Software and Tools: 10%\n",
      "   - Database Experience and Skills: 5%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific database technologies like AWS, Azure, MongoDB, PostgreSQL, which do not fit neatly into the identified themes. These could be considered outliers or could form a separate theme around specific database technologies.\n",
      "   - Some questions mention specific years of experience or certifications, which do not fit neatly into the identified themes. These could be considered outliers or could form a separate theme around qualifications and experience.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 29513\n",
      "\tPrompt Tokens: 24054\n",
      "\tCompletion Tokens: 5459\n",
      "Successful Requests: 12\n",
      "Total Cost (USD): $1.04916\n",
      "\n",
      "Cluster: 5:\n",
      "(1) Main Question Themes:\n",
      "- Software Engineering and Development\n",
      "- Data Science and Analytics\n",
      "- Business Process and Strategy\n",
      "- Health and Medical Data Management\n",
      "- Cloud and SAAS Implementations\n",
      "- Machine Learning and AI\n",
      "- Job Application and Recruitment\n",
      "\n",
      "(2) Representative Example Questions in Each Theme:\n",
      "- Software Engineering and Development: \n",
      "  - \"What is your experience with designing features in collaboration with senior engineers?\"\n",
      "  - \"Can you describe a project where you had to use your knowledge of software development principles?\"\n",
      "- Data Science and Analytics: \n",
      "  - \"Can you describe a time when you identified data quality issues and implemented fixes?\"\n",
      "  - \"How have you used data analytics to drive business decisions?\"\n",
      "- Business Process and Strategy: \n",
      "  - \"Have you ever led teams of 25+ engineers and managed managers?\"\n",
      "  - \"Can you provide an example of a strategic business decision you made and its outcome?\"\n",
      "- Health and Medical Data Management: \n",
      "  - \"How have you used business intelligence applications to enhance clinical & business decision-making capabilities?\"\n",
      "  - \"Can you describe a project where you had to manage health or medical data?\"\n",
      "- Cloud and SAAS Implementations: \n",
      "  - \"Do you have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations?\"\n",
      "  - \"Can you describe a time when you had to troubleshoot a problem in a cloud-based system?\"\n",
      "- Machine Learning and AI: \n",
      "  - \"Can you provide an example of a project where you used machine learning to improve a business process?\"\n",
      "  - \"How have you used AI to solve a complex problem?\"\n",
      "- Job Application and Recruitment: \n",
      "  - \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\"\n",
      "  - \"Can you describe your experience with remote work?\"\n",
      "\n",
      "(3) Estimated Proportion of Questions That Fall into Each Theme:\n",
      "- Software Engineering and Development: 30%\n",
      "- Data Science and Analytics: 25%\n",
      "- Business Process and Strategy: 15%\n",
      "- Health and Medical Data Management: 10%\n",
      "- Cloud and SAAS Implementations: 10%\n",
      "- Machine Learning and AI: 5%\n",
      "- Job Application and Recruitment: 5%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "A few outliers were identified that did not fit into the main themes. These included advertisements for courses and fragments of job postings. These outliers did not provide complete or relevant information and were not included in the main themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_reduce_gpt4_res = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for i in range(len(docs)):\n",
    "        result = run_map_reduce(docs[i], \"gpt-4\",MAP_PROMPT, REDUCE_PROMPT)\n",
    "        map_reduce_gpt4_res.append(result)\n",
    "        print(cb)\n",
    "        print(f\"\\nCluster: {i}:\")\n",
    "        print(result)\n",
    "        print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29513"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 4575\n",
      "\tPrompt Tokens: 3930\n",
      "\tCompletion Tokens: 645\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0071849999999999995\n",
      "\n",
      "Cluster: 0:\n",
      "(1) Main Question Themes:\n",
      "- Data Science Strategy and Leadership\n",
      "- Data Management and Quality\n",
      "- Collaboration and Teamwork\n",
      "- Data Analysis and Insights\n",
      "- Data Infrastructure and Tools\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Data Science Strategy and Leadership:\n",
      "  - \"How can we define and execute a data science and analytics roadmap?\"\n",
      "  - \"What are the best practices for building a data-driven culture within an organization?\"\n",
      "\n",
      "- Data Management and Quality:\n",
      "  - \"How can we ensure data governance, data security, and data quality?\"\n",
      "  - \"What are the key steps in data cleaning and preprocessing to improve data quality?\"\n",
      "\n",
      "- Collaboration and Teamwork:\n",
      "  - \"How can we collaborate with other teams to turn data into critical information and knowledge?\"\n",
      "  - \"What are effective strategies for fostering cross-functional collaboration in data science projects?\"\n",
      "\n",
      "- Data Analysis and Insights:\n",
      "  - \"How can we analyze product data to identify problems and ideate product features?\"\n",
      "  - \"What are the best techniques for extracting actionable insights from large datasets?\"\n",
      "\n",
      "- Data Infrastructure and Tools:\n",
      "  - \"How can we design and build modern data pipelines and data service APIs?\"\n",
      "  - \"What are the recommended tools and technologies for scalable data storage and processing?\"\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Data Science Strategy and Leadership: 15%\n",
      "- Data Management and Quality: 20%\n",
      "- Collaboration and Teamwork: 15%\n",
      "- Data Analysis and Insights: 25%\n",
      "- Data Infrastructure and Tools: 25%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are a few questions that do not fit into any of the main themes, suggesting they may be more specific to the organization or context in which the texts were clustered. These outliers include questions like \"Teach the broader data science team new tools and techniques\" and \"Support discovery of business problems.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 9040\n",
      "\tPrompt Tokens: 7815\n",
      "\tCompletion Tokens: 1225\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.0141725\n",
      "\n",
      "Cluster: 1:\n",
      "Main question themes:\n",
      "1. Experience and qualifications in data science and analytics\n",
      "2. Data engineering and data pipelines\n",
      "3. Data analysis and data visualization\n",
      "4. Technical skills and tools\n",
      "\n",
      "Representative example questions in each theme:\n",
      "1. Experience and qualifications in data science and analytics:\n",
      "- \"Do you have at least 5 years of experience in data science or a related field?\"\n",
      "- \"What qualifications do you have in data science and analytics?\"\n",
      "\n",
      "2. Data engineering and data pipelines:\n",
      "- \"Have you worked on designing and implementing data pipelines?\"\n",
      "- \"What tools and technologies have you used for data engineering?\"\n",
      "\n",
      "3. Data analysis and data visualization:\n",
      "- \"Are you proficient in data analysis and data visualization techniques?\"\n",
      "- \"Can you provide examples of data analysis and visualization projects you have worked on?\"\n",
      "\n",
      "4. Technical skills and tools:\n",
      "- \"Do you have experience with SQL, Python, and cloud technologies?\"\n",
      "- \"What programming languages and tools are you proficient in for data analysis?\"\n",
      "\n",
      "Proportion of questions that fall into each theme:\n",
      "1. Experience and qualifications in data science and analytics: Approximately 30% of the questions.\n",
      "2. Data engineering and data pipelines: Approximately 20% of the questions.\n",
      "3. Data analysis and data visualization: Approximately 15% of the questions.\n",
      "4. Technical skills and tools: Approximately 15% of the questions.\n",
      "\n",
      "Summary of outliers:\n",
      "There are a few questions that do not fit into any specific theme, such as inquiries about management experience, agile methodology, and specific software or technology experience. These questions may be more specific to certain job roles or industries and are considered outliers in the overall question themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 13464\n",
      "\tPrompt Tokens: 11697\n",
      "\tCompletion Tokens: 1767\n",
      "Successful Requests: 6\n",
      "Total Cost (USD): $0.021079499999999998\n",
      "\n",
      "Cluster: 2:\n",
      "(1) Main Question Themes:\n",
      "- Business Intelligence Development\n",
      "- Business Analysis and Requirements Gathering\n",
      "- Data Analysis and Reporting\n",
      "- Project Management and Process Improvement\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Business Intelligence Development:\n",
      "  - \"As a Business Intelligence Developer, what are your responsibilities in creating analytical reports and dashboards?\"\n",
      "  - \"How do you ensure the accuracy and reliability of the data used in your analytical reports and dashboards?\"\n",
      "\n",
      "- Business Analysis and Requirements Gathering:\n",
      "  - \"How do you gather and document business requirements for business processes and reports?\"\n",
      "  - \"What techniques do you use to prioritize and validate business requirements?\"\n",
      "\n",
      "- Data Analysis and Reporting:\n",
      "  - \"What experience do you have in analyzing data to draw business-relevant conclusions and creating analytical reports?\"\n",
      "  - \"Can you provide an example of a complex data analysis project you have worked on and the insights you derived from it?\"\n",
      "\n",
      "- Project Management and Process Improvement:\n",
      "  - \"How do you lead the process for identifying and gathering appropriate business requirements to create necessary solutions?\"\n",
      "  - \"What strategies do you employ to ensure successful project delivery and continuous process improvement?\"\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Business Intelligence Development: 20%\n",
      "- Business Analysis and Requirements Gathering: 30%\n",
      "- Data Analysis and Reporting: 30%\n",
      "- Project Management and Process Improvement: 20%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are no clear outliers in this list of questions. However, some questions may overlap across themes, such as questions related to data analysis and reporting that also involve business intelligence development.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 18288\n",
      "\tPrompt Tokens: 15756\n",
      "\tCompletion Tokens: 2532\n",
      "Successful Requests: 8\n",
      "Total Cost (USD): $0.028697999999999998\n",
      "\n",
      "Cluster: 3:\n",
      "(1) Main Question Themes:\n",
      "a) Machine Learning Expertise\n",
      "b) Data Science and Analytics\n",
      "c) AI and ML Applications\n",
      "d) Machine Learning Infrastructure\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "a) Machine Learning Expertise:\n",
      "- What is your experience with modern machine learning theories and frameworks?\n",
      "- Can you provide an example of a machine learning model you have developed and deployed?\n",
      "\n",
      "b) Data Science and Analytics:\n",
      "- How would you approach solving a classification or clustering problem using machine learning algorithms?\n",
      "- Can you explain the concept of feature engineering and its importance in machine learning?\n",
      "\n",
      "c) AI and ML Applications:\n",
      "- How would you use machine learning to deliver actionable insights and accurate predictions in strategic communications?\n",
      "- Can you describe a project where you applied machine learning to improve ad recommendation?\n",
      "\n",
      "d) Machine Learning Infrastructure:\n",
      "- How would you scale and manage machine learning models in a production environment?\n",
      "- Can you explain the process of developing a hosting platform for machine learning models?\n",
      "\n",
      "(3) Proportion of Questions in Each Theme:\n",
      "a) Machine Learning Expertise: 30%\n",
      "b) Data Science and Analytics: 25%\n",
      "c) AI and ML Applications: 30%\n",
      "d) Machine Learning Infrastructure: 15%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are a few questions that do not fit into any specific theme, such as inquiries about publications at major machine learning conferences or in major scientific journals, and questions about free training and placement opportunities in data science. These questions may be more specific or niche in nature and may not align with the broader themes identified.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 22995\n",
      "\tPrompt Tokens: 19710\n",
      "\tCompletion Tokens: 3285\n",
      "Successful Requests: 10\n",
      "Total Cost (USD): $0.036135\n",
      "\n",
      "Cluster: 4:\n",
      "(1) Main Question Themes:\n",
      "- Database administration and management\n",
      "- Database performance optimization\n",
      "- Database security and access control\n",
      "- Database backup and recovery\n",
      "- Database design and schema\n",
      "- Database troubleshooting and problem-solving\n",
      "- Cloud database technologies\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Database administration and management:\n",
      "  - What are the responsibilities of a database administrator?\n",
      "  - How can database performance be monitored and managed effectively?\n",
      "- Database performance optimization:\n",
      "  - How can database performance be improved?\n",
      "  - What are the common bottlenecks that affect database performance?\n",
      "- Database security and access control:\n",
      "  - What measures can be taken to secure a database?\n",
      "  - How can user access and permissions be managed in a database?\n",
      "- Database backup and recovery:\n",
      "  - What are the best practices for database backup and recovery?\n",
      "  - How can data integrity be ensured during the backup and recovery process?\n",
      "- Database design and schema:\n",
      "  - How can a database schema be designed for optimal performance?\n",
      "  - What factors should be considered when designing a database schema?\n",
      "- Database troubleshooting and problem-solving:\n",
      "  - How can database performance issues be diagnosed and resolved?\n",
      "  - What are the common techniques for troubleshooting database problems?\n",
      "- Cloud database technologies:\n",
      "  - What are the advantages and disadvantages of using cloud databases?\n",
      "  - How can data migration to a cloud database be performed efficiently?\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Database administration and management: 20%\n",
      "- Database performance optimization: 15%\n",
      "- Database security and access control: 10%\n",
      "- Database backup and recovery: 10%\n",
      "- Database design and schema: 10%\n",
      "- Database troubleshooting and problem-solving: 20%\n",
      "- Cloud database technologies: 15%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "- There are a few outlier questions that do not seem to belong to any specific theme, such as \"Pay rate is very flexible!\" and \"Exciting opportunity for recent college grads!\" These questions may be related to job postings or specific opportunities rather than general database topics. These outliers should be disregarded as they do not contribute to the main question themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 27171\n",
      "\tPrompt Tokens: 23273\n",
      "\tCompletion Tokens: 3898\n",
      "Successful Requests: 12\n",
      "Total Cost (USD): $0.0427055\n",
      "\n",
      "Cluster: 5:\n",
      "Main Question Themes:\n",
      "1. Job Descriptions/Requirements\n",
      "2. Company Information\n",
      "3. Technical Skills/Experience\n",
      "4. Data Science/Analytics\n",
      "\n",
      "Representative Example Questions:\n",
      "1. Job Descriptions/Requirements:\n",
      "   - \"Do you have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations?\"\n",
      "   - \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\"\n",
      "\n",
      "2. Company Information:\n",
      "   - \"What is the mission of Spring Health?\"\n",
      "   - \"What is the annual base salary range for this position?\"\n",
      "\n",
      "3. Technical Skills/Experience:\n",
      "   - \"Do you have experience with Python?\"\n",
      "   - \"Do you have experience in front-end web development?\"\n",
      "\n",
      "4. Data Science/Analytics:\n",
      "   - \"What data solutions and technologies do you use at 84.51°?\"\n",
      "   - \"What statistical modeling techniques are commonly used in your data analysis process?\"\n",
      "\n",
      "Proportion of Questions:\n",
      "1. Job Descriptions/Requirements: Approximately 20% of the questions fall into this theme.\n",
      "2. Company Information: Approximately 10% of the questions fall into this theme.\n",
      "3. Technical Skills/Experience: Approximately 15% of the questions fall into this theme.\n",
      "4. Data Science/Analytics: Approximately 10% of the questions fall into this theme.\n",
      "\n",
      "Summary of Outliers:\n",
      "There are a few questions that do not fit into any specific theme. These outliers may be related to specific job postings or may be unrelated to the main themes identified. Examples of such questions include \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\" and \"What is the annual base salary range for this position?\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_reduce_gpt35_res = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for i in range(len(docs)):\n",
    "        result = run_map_reduce(docs[i], \"gpt-3.5-turbo\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "        map_reduce_gpt35_res.append(result)\n",
    "        print(cb)\n",
    "        print(f\"\\nCluster: {i}:\")\n",
    "        print(result)\n",
    "        print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27171"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "input_doc = '\\n\\n'.join(docs)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=4000,chunk_overlap=0,separator=\"\\n\\n\")\n",
    "# Sanity check\n",
    "len(text_splitter.split_text(input_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Topic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template_string = template = \"\"\"The following is a list of summaries:\n",
    "{question_summaries}\n",
    "\n",
    "Take these and distill it into a final, consolidated list with: \n",
    "(1) the top 5 texts related to AI and ML applications.\n",
    "(2) estimate the proportion of each question\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"question_summaries\"], template=reduce_template_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 717\n",
      "\tPrompt Tokens: 482\n",
      "\tCompletion Tokens: 235\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.028559999999999995\n",
      "(1) Top 5 Texts Related to AI and ML Applications:\n",
      "   - \"What experience do you have in developing and deploying machine learning models for ad recommendation?\"\n",
      "   - \"Can you provide examples of your proficiency with data mining and machine learning?\"\n",
      "   - \"What is your understanding of various advanced analytical and machine learning methods?\"\n",
      "   - \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\"\n",
      "   - \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\"\n",
      "\n",
      "(2) Estimated Proportion of Each Question:\n",
      "   - \"What experience do you have in developing and deploying machine learning models for ad recommendation?\" - 30%\n",
      "   - \"Can you provide examples of your proficiency with data mining and machine learning?\" - 20%\n",
      "   - \"What is your understanding of various advanced analytical and machine learning methods?\" - 15%\n",
      "   - \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\" - 15%\n",
      "   - \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\" - 10%\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = run_map_reduce(docs[3], \"gpt-4\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 610\n",
      "\tPrompt Tokens: 509\n",
      "\tCompletion Tokens: 101\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0009655000000000001\n",
      "(1) The top 5 texts related to AI and ML applications are:\n",
      "- Strategic Communications\n",
      "- Ad Recommendation\n",
      "- Natural Language Processing\n",
      "- Computer Vision\n",
      "- Image Processing\n",
      "\n",
      "(2) The estimated proportion of each question is:\n",
      "- Machine Learning Expertise: 30%\n",
      "- Data Science and Analytics: 25%\n",
      "- AI and ML Applications: 30%\n",
      "- Machine Learning Infrastructure: 15%\n",
      "- Outliers: 0% (since they do not fit into any specific theme)\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = run_map_reduce(docs[3], \"gpt-3.5-turbo\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
