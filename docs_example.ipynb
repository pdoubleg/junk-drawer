{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with GPT-3.5-turbo, GPT-4, and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset is 1,200 DS related job posting from Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/data_science_jobs_indeed_usa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.assign(token_count=df['Description'].apply(lambda x: len(encoding.encode(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IT Business Intelligence Developer (FT) Remote...</td>\n",
       "      <td>Ballad Health</td>\n",
       "      <td>Remote in Blountville, TN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Details Apply Save Print this job Email a…</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=58612836c63b8...</td>\n",
       "      <td>Job Details\\nApply\\nSave\\nPrint this job\\nEmai...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Longevity Holdings Inc.</td>\n",
       "      <td>Remote in Minneapolis-Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 3 days ago</td>\n",
       "      <td>$90,000 - $110,000 a year</td>\n",
       "      <td>Incorporate core data management competencies ...</td>\n",
       "      <td>https://www.indeed.com/company/TwentyFirst/job...</td>\n",
       "      <td>Position: Data Engineer\\nLocation: MN\\nAs a Da...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Network Administrator/dba developer</td>\n",
       "      <td>WKI Kenworth</td>\n",
       "      <td>Wichita, KS 67219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EmployerActive 2 days ago</td>\n",
       "      <td>$50,000 - $70,000 a year</td>\n",
       "      <td>The Network Administrator provides 2nd level e...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Full Job Description\\nThe Network Administrato...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                                     Data Scientist   \n",
       "1           1                                   Business Analyst   \n",
       "2           2  IT Business Intelligence Developer (FT) Remote...   \n",
       "3           3                                      Data Engineer   \n",
       "4           4                Network Administrator/dba developer   \n",
       "\n",
       "                   Company                              Location  Rating  \\\n",
       "0            Driven Brands                           Benicia, CA     2.4   \n",
       "1         Sabot Consulting                                Remote     NaN   \n",
       "2            Ballad Health             Remote in Blountville, TN     3.0   \n",
       "3  Longevity Holdings Inc.  Remote in Minneapolis-Saint Paul, MN     NaN   \n",
       "4             WKI Kenworth                     Wichita, KS 67219     NaN   \n",
       "\n",
       "                        Date                     Salary  \\\n",
       "0   PostedPosted 26 days ago                        NaN   \n",
       "1    PostedPosted 4 days ago         $80 - $120 an hour   \n",
       "2  PostedPosted 30+ days ago                        NaN   \n",
       "3    PostedPosted 3 days ago  $90,000 - $110,000 a year   \n",
       "4  EmployerActive 2 days ago   $50,000 - $70,000 a year   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "2     Job Details Apply Save Print this job Email a…   \n",
       "3  Incorporate core data management competencies ...   \n",
       "4  The Network Administrator provides 2nd level e...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "2  https://www.indeed.com/rc/clk?jk=58612836c63b8...   \n",
       "3  https://www.indeed.com/company/TwentyFirst/job...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                        Descriptions  token_count  \n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26  \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25  \n",
       "2  Job Details\\nApply\\nSave\\nPrint this job\\nEmai...           10  \n",
       "3  Position: Data Engineer\\nLocation: MN\\nAs a Da...           29  \n",
       "4  Full Job Description\\nThe Network Administrato...           28  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure: \n",
    "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "# def get_embedding(text) -> list[float]:\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "#     return openai.Embedding.create(input=text, engine=OpenAiEmbedding)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "# def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "#    text = text.replace(\"\\n\", \" \")\n",
    "#    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.assign(embedding=df['Description'].apply(lambda x: get_embedding(x, model='text-embedding-ada-002')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_parquet(\"job_descriptions_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m\"\u001b[39m\u001b[39mjob_descriptions_with_embeddings.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"job_descriptions_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IT Business Intelligence Developer (FT) Remote...</td>\n",
       "      <td>Ballad Health</td>\n",
       "      <td>Remote in Blountville, TN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>Job Details Apply Save Print this job Email a…</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=58612836c63b8...</td>\n",
       "      <td>Job Details\\nApply\\nSave\\nPrint this job\\nEmai...</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.021908748894929886, -0.002960818586871028,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Longevity Holdings Inc.</td>\n",
       "      <td>Remote in Minneapolis-Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 3 days ago</td>\n",
       "      <td>$90,000 - $110,000 a year</td>\n",
       "      <td>Incorporate core data management competencies ...</td>\n",
       "      <td>https://www.indeed.com/company/TwentyFirst/job...</td>\n",
       "      <td>Position: Data Engineer\\nLocation: MN\\nAs a Da...</td>\n",
       "      <td>29</td>\n",
       "      <td>[-0.017482835799455643, -0.01076465379446745, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Network Administrator/dba developer</td>\n",
       "      <td>WKI Kenworth</td>\n",
       "      <td>Wichita, KS 67219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EmployerActive 2 days ago</td>\n",
       "      <td>$50,000 - $70,000 a year</td>\n",
       "      <td>The Network Administrator provides 2nd level e...</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Full Job Description\\nThe Network Administrato...</td>\n",
       "      <td>28</td>\n",
       "      <td>[0.0011034636991098523, -0.000915585900656879,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                                     Data Scientist   \n",
       "1           1                                   Business Analyst   \n",
       "2           2  IT Business Intelligence Developer (FT) Remote...   \n",
       "3           3                                      Data Engineer   \n",
       "4           4                Network Administrator/dba developer   \n",
       "\n",
       "                   Company                              Location  Rating  \\\n",
       "0            Driven Brands                           Benicia, CA     2.4   \n",
       "1         Sabot Consulting                                Remote     NaN   \n",
       "2            Ballad Health             Remote in Blountville, TN     3.0   \n",
       "3  Longevity Holdings Inc.  Remote in Minneapolis-Saint Paul, MN     NaN   \n",
       "4             WKI Kenworth                     Wichita, KS 67219     NaN   \n",
       "\n",
       "                        Date                     Salary  \\\n",
       "0   PostedPosted 26 days ago                       None   \n",
       "1    PostedPosted 4 days ago         $80 - $120 an hour   \n",
       "2  PostedPosted 30+ days ago                       None   \n",
       "3    PostedPosted 3 days ago  $90,000 - $110,000 a year   \n",
       "4  EmployerActive 2 days ago   $50,000 - $70,000 a year   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "2     Job Details Apply Save Print this job Email a…   \n",
       "3  Incorporate core data management competencies ...   \n",
       "4  The Network Administrator provides 2nd level e...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "2  https://www.indeed.com/rc/clk?jk=58612836c63b8...   \n",
       "3  https://www.indeed.com/company/TwentyFirst/job...   \n",
       "4  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "2  Job Details\\nApply\\nSave\\nPrint this job\\nEmai...           10   \n",
       "3  Position: Data Engineer\\nLocation: MN\\nAs a Da...           29   \n",
       "4  Full Job Description\\nThe Network Administrato...           28   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...  \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...  \n",
       "2  [-0.021908748894929886, -0.002960818586871028,...  \n",
       "3  [-0.017482835799455643, -0.01076465379446745, ...  \n",
       "4  [0.0011034636991098523, -0.000915585900656879,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df.embedding.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `n_clusters=6` is arbitrary & just for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "df['kmeans_label'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Sabot Consulting</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostedPosted 4 days ago</td>\n",
       "      <td>$80 - $120 an hour</td>\n",
       "      <td>Preferred candidates will have prior experienc...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=f662b2efb509b...</td>\n",
       "      <td>Sabot Consulting (Sabot) is a management consu...</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.012073525227606297, -0.026480479165911674,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Title           Company     Location  Rating  \\\n",
       "0           0    Data Scientist     Driven Brands  Benicia, CA     2.4   \n",
       "1           1  Business Analyst  Sabot Consulting       Remote     NaN   \n",
       "\n",
       "                       Date              Salary  \\\n",
       "0  PostedPosted 26 days ago                None   \n",
       "1   PostedPosted 4 days ago  $80 - $120 an hour   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "1  Preferred candidates will have prior experienc...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "1  https://www.indeed.com/rc/clk?jk=f662b2efb509b...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "1  Sabot Consulting (Sabot) is a management consu...           25   \n",
       "\n",
       "                                           embedding  kmeans_label  \n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4  \n",
       "1  [-0.012073525227606297, -0.026480479165911674,...             2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1200.000000\n",
       "mean       26.441667\n",
       "std         4.249507\n",
       "min         9.000000\n",
       "25%        24.000000\n",
       "50%        26.000000\n",
       "75%        29.000000\n",
       "max        45.000000\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.token_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_index.token_catcher import Usage\n",
    "\n",
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import SQLiteCache\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "class ClusterTopicLabeler:\n",
    "    \"\"\"\n",
    "    A class to label clusters of texts with topic titles using the LangChain library.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the clusters and texts.\n",
    "    cluster_column : str\n",
    "        The name of the column in df that contains the cluster labels.\n",
    "    text_column : str\n",
    "        The name of the column in df that contains the texts.\n",
    "    max_paragraphs : int\n",
    "        The maximum number of paragraphs that can be processed at once.\n",
    "    avg_tokens_per_paragraph : int\n",
    "        The average number of tokens per paragraph.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    get_prompt():\n",
    "        Returns the prompt for the LangChain model.\n",
    "    label_clusters():\n",
    "        Labels the clusters in df with topic titles.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, cluster_column, text_column, max_tokens=4096):\n",
    "        \"\"\"\n",
    "        Constructs all the necessary attributes for the ClusterTopicLabeler object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            The DataFrame containing the clusters and texts.\n",
    "        cluster_column : str\n",
    "            The name of the column in df that contains the cluster labels.\n",
    "        text_column : str\n",
    "            The name of the column in df that contains the texts.\n",
    "        max_tokens : int\n",
    "            The maximum number of tokens that can be processed at once by the model.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.cluster_column = cluster_column\n",
    "        self.text_column = text_column\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "        # Initialize a Tiktoken tokenizer\n",
    "        self.encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "        \n",
    "        # Calculate the average number of tokens per paragraph\n",
    "        self.avg_tokens_per_paragraph = df[text_column].apply(self.count_tokens).mean()\n",
    "\n",
    "        # Calculate the maximum number of paragraphs that can be processed at once\n",
    "        self.max_paragraphs = max_tokens // self.avg_tokens_per_paragraph\n",
    "        \n",
    "    \n",
    "    def count_tokens(self, text):\n",
    "        \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "        num_tokens = len(self.encoding.encode(text))\n",
    "        return num_tokens\n",
    "\n",
    "    \n",
    "    def get_prompt(self):\n",
    "        \"\"\"\n",
    "        Returns the prompt for the LangChain model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ChatPromptTemplate\n",
    "            The prompt for the LangChain model.\n",
    "        \"\"\"\n",
    "        system_template = \"You're an expert journalist. You're helping me write a compelling topic title for news articles.\"\n",
    "        human_template = \"Using the following articles, write a topic title that summarizes them.\\n\\nARTICLES:{articles}\\n\\nTOPIC TITLE:\"\n",
    "\n",
    "        return ChatPromptTemplate(\n",
    "            messages=[\n",
    "                SystemMessagePromptTemplate.from_template(system_template),\n",
    "                HumanMessagePromptTemplate.from_template(human_template),\n",
    "            ],\n",
    "            input_variables=[\"articles\"],\n",
    "        )\n",
    "\n",
    "    \n",
    "    def get_text_groups(self, texts):\n",
    "        \"\"\"\n",
    "        Groups the texts based on the token limit.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        texts : list\n",
    "            The list of texts to be grouped.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            The grouped texts.\n",
    "        \"\"\"\n",
    "        # Create a DataFrame for easier manipulation\n",
    "        df = pd.DataFrame(texts, columns=[\"text\"])\n",
    "\n",
    "        # Add a new column to the DataFrame representing the token count of each text\n",
    "        df['tokens'] = df['text'].apply(lambda x: self.count_tokens(x))\n",
    "\n",
    "        # Calculate cumulative token count\n",
    "        df['cumulative_tokens'] = df['tokens'].cumsum()\n",
    "\n",
    "        # Create groups based on the token limit\n",
    "        df['group'] = (df['cumulative_tokens'] // self.avg_tokens_per_paragraph).astype(int)\n",
    "\n",
    "        # Ensure that the distribution of the text lengths in each group \n",
    "        # matches the overall distribution of the text lengths\n",
    "        df = df.sample(frac=1).groupby('group').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\n",
    "\n",
    "        # Create groups\n",
    "        groups = df.groupby('group')['text'].apply(list).values\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def label_clusters(self):\n",
    "        \"\"\"\n",
    "        Labels the clusters in df with topic titles.\n",
    "\n",
    "        The generated topic titles are assigned to a new column 'topic_title' in df.\n",
    "        \"\"\"\n",
    "        for c in self.df[self.cluster_column].unique():\n",
    "            chain = LLMChain(\n",
    "                llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), prompt=self.get_prompt(), verbose=False\n",
    "            )\n",
    "            articles = self.df[self.df[self.cluster_column] == c][self.text_column].tolist()\n",
    "\n",
    "            # Get the groups of articles based on the token limit\n",
    "            article_groups = self.get_text_groups(articles)\n",
    "\n",
    "            # Process the article groups\n",
    "            for group in article_groups:\n",
    "                group_str = \"\\n\".join(group)\n",
    "                result = chain.run(\n",
    "                    {\n",
    "                        \"articles\": group_str,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Assign the generated topic title to each article in the group\n",
    "                for article in group:\n",
    "                    self.df.loc[self.df[self.text_column] == article, \"topic_title\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Links</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "      <th>kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Driven Brands</td>\n",
       "      <td>Benicia, CA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>PostedPosted 26 days ago</td>\n",
       "      <td>None</td>\n",
       "      <td>You’ll be working alongside a team of eight an...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=74d176d595225...</td>\n",
       "      <td>We invite you to join us at Driven Brands!\\nHe...</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0194996390491724, -0.0041993726044893265, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Title        Company     Location  Rating  \\\n",
       "0           0  Data Scientist  Driven Brands  Benicia, CA     2.4   \n",
       "\n",
       "                       Date Salary  \\\n",
       "0  PostedPosted 26 days ago   None   \n",
       "\n",
       "                                         Description  \\\n",
       "0  You’ll be working alongside a team of eight an...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=74d176d595225...   \n",
       "\n",
       "                                        Descriptions  token_count  \\\n",
       "0  We invite you to join us at Driven Brands!\\nHe...           26   \n",
       "\n",
       "                                           embedding  kmeans_label  \n",
       "0  [-0.0194996390491724, -0.0041993726044893265, ...             4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = ClusterTopicLabeler(df, \"kmeans_label\", \"Description\", max_tokens=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_index.token_catcher import Usage\n",
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Tue, 01 Aug 2023 02:13:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7efa88145f8747a8-DFW', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
   "source": [
    "labeler.label_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95942"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = labeler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_parquet(\"ClusterLabelerTestResults.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res_df = pd.read_parquet(\"ClusterLabelerTestResults.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import langchain\n",
    "# from langchain.cache import SQLiteCache\n",
    "# langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "system_template = \"You're an expert journalist. You're helping me write a concise topic title for job descriptions.\"\n",
    "human_template = \"Using the following job description, write a concise tag line.\\n\\nDESCRIPTIONS:{Description}\\n\\nTAG LINE:\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(system_template),\n",
    "        HumanMessagePromptTemplate.from_template(human_template),\n",
    "    ],\n",
    "    input_variables=[\"Description\"],\n",
    ")\n",
    "    \n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"), prompt=prompt, verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = res_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_chain = sample_df[[\"Description\"]].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await chain.aapply(list_to_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "sem = asyncio.Semaphore(50)\n",
    "\n",
    "async def delay_wrapper(func, *args, **kwargs):\n",
    "    async with sem:\n",
    "        result = await func(*args, **kwargs)\n",
    "    await asyncio.sleep(2)  # 2 second delay\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await delay_wrapper(chain.aapply, list_to_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\"Expert in building scalable machine learning systems and pipelines\"'},\n",
       " {'text': '\"Immediate interview and excellent pay rate for Iowa Department of Public Health Center for Acute opportunity\"'},\n",
       " {'text': '\"Data Manager: Leading the Way in Efficient Data Management Systems\"'},\n",
       " {'text': 'Data Pipeline Manager: Scaling and Enhancing Data Quality for Product Launches'},\n",
       " {'text': '\"Signal Builder: Utilizing Data and Machine Learning for Macro Asset Forecasting\"'},\n",
       " {'text': '\"Experienced Health Insurance Professional with Business Intelligence and Strong Communication Skills\"'},\n",
       " {'text': '\"Experienced Machine Learning Expert with 10+ years of expertise in clustering, decision tree learning, and artificial neural networks\"'},\n",
       " {'text': '\"Machine Learning Expert: Solving Classification, Clustering, and Information Retrieval Challenges\"'},\n",
       " {'text': '\"Experienced Machine Learning Analyst: Analyzing and Ranking Deep Learning Algorithms for Problem Solving\"'},\n",
       " {'text': '\"Database Security Manager: Proactive Decision-Making for Effective Implementation\"'},\n",
       " {'text': '\"Nurse Data Miners: Uncover Hidden Records for Enhanced Data Collection\"'},\n",
       " {'text': 'Experienced Data Engineer/Analyst: Connecting Systems, Training Users'},\n",
       " {'text': '\"Experienced SQL Server Professional with Expertise in T-SQL, Stored Procedures, and Azure SQL\"'},\n",
       " {'text': '\"Technical Expertise in Customer Data Platforms and ML for a Hybrid Work Model\"'},\n",
       " {'text': 'Experienced Data Scientist Driving Business Success'},\n",
       " {'text': '\"Experienced Data Science Leader: Leading and Growing High-Performing Analytics Teams\"'},\n",
       " {'text': '\"Computer Vision Expert: Driving Caris\\' Research Initiatives with Machine Learning Algorithms\"'},\n",
       " {'text': '\"Customer Data Strategy Leader: Driving Alignment and Innovation\"'},\n",
       " {'text': 'Experienced PM specializing in data-driven product development'},\n",
       " {'text': '\"Data Engineer: Empowering Data-driven Success\"'},\n",
       " {'text': '\"Data Architect: Shaping Internal Structures for Informed Business Decisions\"'},\n",
       " {'text': '\"Data Analyst: Uncovering Opportunities and Insights in Data Center Delivery\"'},\n",
       " {'text': '\"Data Science Engine Lead - Defining and Managing Pipeline Pilot on 3DEXPERIENCE Platform\"'},\n",
       " {'text': '\"Continuous Learning and Technical Development in Data Science\"'},\n",
       " {'text': '\"Empowering Client-Facing Report Builders with Business Intelligence Expertise\"'},\n",
       " {'text': '\"Data Analyst: Uncovering Actionable Insights through Statistical Techniques and A/B Testing\"'},\n",
       " {'text': '\"Multiple Locations, One Opportunity: Join our Sales & Marketing Team!\"'},\n",
       " {'text': '\"Sports Business Analyst: Combining Passion for Sports with Analytical Expertise\"'},\n",
       " {'text': '\"Seeking candidates with machine learning expertise and a commercial mindset\"'},\n",
       " {'text': '\"Manager, Sport Science Data - Driving Football Research & Development\"'},\n",
       " {'text': '\"Experienced Data Analyst: Solving Business Problems through Data Analysis and Mining\"'},\n",
       " {'text': '\"Experienced Data Scientist with Strategic Marketing and Digital Media Expertise, Specializing in Social Media Platforms. Includes Paid Maternity and Paternity Leave.\"'},\n",
       " {'text': '\"Expertly applying subject expertise to deliver innovative solutions while adhering to policies and procedures\"'},\n",
       " {'text': '\"Join a stealth mode start up as a Machine Learning Engineer and revolutionize the music industry with cutting-edge machine learning models.\"'},\n",
       " {'text': '\"Experienced Data Scientist with Strong Analytical Background\"'},\n",
       " {'text': '\"Seeking a Machine Learning Expert with Advanced Analytical Skills and Proficiency in Frameworks\"'},\n",
       " {'text': '\"Analytical Expertise and Relationship Management for Manufacturing Success\"'},\n",
       " {'text': '\"Experienced Data Scientist: Delivering Results in Cross-Functional Teams\"'},\n",
       " {'text': '\"Configuration Specifications and Business Analysis Expert\"'},\n",
       " {'text': '\"Data Engineer: Automating Data Tasks for Efficient Collaboration\"'},\n",
       " {'text': '\"Data Engineer: Optimizing Data Delivery for Efficient Analysis and Insights\"'},\n",
       " {'text': '\"Collaborative problem-solving and effective communication for business success\"'},\n",
       " {'text': '\"Collaborative Report Design: Transforming Data into Actionable Insights\"'},\n",
       " {'text': '\"Transforming Business KPIs into Actionable Insights: Join our team as a Dashboard and Reporting Analyst\"'},\n",
       " {'text': '\"Efficiently translate business needs into actionable product backlog items in an agile environment\"'},\n",
       " {'text': '\"Expert Data Engineer: Scaling Solutions for Complex Data Challenges\"'},\n",
       " {'text': '\"Data Science Project Lead: Driving Innovation and Collaboration Across Teams\"'},\n",
       " {'text': '\"Data Engineer: Expert in Peer Reviews and Automated Data Pipelines\"'},\n",
       " {'text': 'Data Source Assessment and Cataloging: Collaborating with IT and the Analytic Community for Customer Touchpoints'},\n",
       " {'text': '\"Experienced Data Engineer and Database Administrator with Strong Programming Skills\"'},\n",
       " {'text': '\"Flexible Work Program: Tailored to Meet Your Needs\"'},\n",
       " {'text': '\"Experienced Project Manager for Data Scientists and Machine Learning Engineers\"'},\n",
       " {'text': '\"Data Quality Expert: Solving Complex Client Challenges\"'},\n",
       " {'text': '\"Experienced MS SQL Database Administrator: Automating Tasks for Efficiency\"'},\n",
       " {'text': 'Experienced Business Analyst: Reverse Engineering for Transformation Support'},\n",
       " {'text': '\"Expert Bioinformatician: Unlocking Insights from Variant Data and Phenotype Correlation\"'},\n",
       " {'text': '\"Optimize ML model deployment and inferencing for high-performance marketplace\"'},\n",
       " {'text': '\"Leading AI/ML/Data Science R&D projects and fostering customer relationships\"'},\n",
       " {'text': '\"Cutting-edge Data Scientists Solving Business Problems with Data-driven Solutions\"'},\n",
       " {'text': '\"Seeking a Business System Analyst for expertly written and structured business requirements and cloud technical support.\"'},\n",
       " {'text': \"On-Site Engineer: Upgrading Nexus 5K, 7K, and 9K for Client's Facility\"},\n",
       " {'text': '\"Database Performance Optimization and Auditing Expert\"'},\n",
       " {'text': '\"Database Performance Evaluation and Troubleshooting Expert\"'},\n",
       " {'text': '\"Expert Machine Learning Engineer: Optimizing and Deploying Novel Models for RNA Structure\"'},\n",
       " {'text': '\"Collaborative problem-solving and effective communication for business success\"'},\n",
       " {'text': '\"Seeking Senior Engineer to Develop User-Friendly RPC and Data Modeling Platform\"'},\n",
       " {'text': '\"Experienced Business Systems Analyst: Translating User Requirements for Optimal Results\"'},\n",
       " {'text': '\"Data Engineer: Building and Optimizing Data Modules and Pipelines with Big Data Technologies\"'},\n",
       " {'text': '\"Experienced Data Scientist: Innovating with Technology in a Collaborative Environment\"'},\n",
       " {'text': '\"Driving Analytic Initiatives for Business Success\"'},\n",
       " {'text': '\"Seeking Migration Engineers for Enterprise Data Center Migration Project\"'},\n",
       " {'text': '\"Power BI Expert: Building and Enhancing Reports for Efficient Business Insights\"'},\n",
       " {'text': '\"Business Intelligence Solutions Expert: Enhancing Business Processes with Data-driven Reports\"'},\n",
       " {'text': '\"Strategic Decision-Making Partner: Join a Transparent, Ground-Floor Opportunity\"'},\n",
       " {'text': '\"Unlocking Big Data Insights: Join our team of collaborative data scientists!\"'},\n",
       " {'text': '\"Data Science Expert: Driving Business Outcomes and Patient Impact\"'},\n",
       " {'text': '\"Data-driven insights: Uncover user behavior through quantitative analysis and data mining\"'},\n",
       " {'text': 'Data Architect and QA Specialist'},\n",
       " {'text': '\"Business Intelligence Training and Collaboration: Empowering Users and Driving Success\"'},\n",
       " {'text': '\"Experienced Talent Recruiter for Data Roles: Lead a Team of Data Engineers and Drive Strategy\"'},\n",
       " {'text': 'Technical Liaison: Bridging the Gap Between I/S and Business Areas'},\n",
       " {'text': '\"Database Management Expert: Design, Develop, Implement, and Support\"'},\n",
       " {'text': '\"Database Administrator: Ensuring Optimal Database Performance and Structure\"'},\n",
       " {'text': '\"Requirements-driven Machine Learning Engineer: Enhancing Models and Driving Impact\"'},\n",
       " {'text': '\"Expert Customer Predictive Modeler with Applied Experience in Attribute Screening and 3rd Party Data Integration\"'},\n",
       " {'text': '\"Streamline data processing with a skilled Database Administrator\"'},\n",
       " {'text': '\"Data-driven problem solver: Utilizing business acumen to uncover and resolve challenges.\"'},\n",
       " {'text': '\"Data Design and Development Specialist\"'},\n",
       " {'text': '\"Data-driven strategist needed to unlock growth opportunities and drive business success\"'},\n",
       " {'text': '\"Data Lake Expert with Oracle and SQL Experience\"'},\n",
       " {'text': '\"Arch Insurance: Expert Underwriting and Risk Selection for All Businesses\"'},\n",
       " {'text': '\"Collaborative Engineering Opportunity with Ezoic, a Google Certified Publishing Partner\"'},\n",
       " {'text': '\"Expanding Product Capabilities through Innovative Machine Learning Algorithms\"'},\n",
       " {'text': '\"Expert Database Administrator with Strong Performance Tuning Skills\"'},\n",
       " {'text': '\"Leading the Way in Data Science: Hiring, Training, and Retaining Top Talent\"'},\n",
       " {'text': '\"Join [redacted] Engineering as a React Web Developer and revolutionize data-driven design and user experience!\"'},\n",
       " {'text': '\"Scaling Business with Cutting-Edge Data Science and Machine Learning Techniques\"'},\n",
       " {'text': '\"Analyzing Solutions for Optimal Business Impact\"'},\n",
       " {'text': '\"Empowering individuals and organizations to customize software for limitless problem-solving\"'},\n",
       " {'text': '\"Data Catalog Steward Training and Administration: Enhancing Data Management Efficiency\"'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': 'Develop hosting platform for machine learning models.\\nSupervise the scaling and management of the machine learning modeling ecosystem.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_chain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.callbacks import get_openai_callback\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 34\n",
      "\tPrompt Tokens: 11\n",
      "\tCompletion Tokens: 23\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $6.25e-05\n",
      "Sure, here's a classic one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.predict(\"Tell me a joke\")\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "Sure, here's a classic one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.predict(\"Tell me a joke\")\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69269"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topics by Cluster Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 has 0    281\n",
      "Name: 4, dtype: int64 messages\n",
      "['Familiarity with data visualization tools.\\nComfortable pulling and manipulating data using SQL.\\nParticipates in and oversees the Data Science team in analyzing…'\n",
      " \"This team's key partners include other product teams, finance, data science, and other teams within data engineering.\"\n",
      " 'A storyteller, be able to make sense of data and extrapolate meaningful and actionable insights.\\nUse website data to create compelling stories and succinct…'\n",
      " 'Set data standards and oversee stewardship, ensuring that all products and services have data standards built in from the start.']\n",
      "\n",
      "\n",
      "3 has 0    274\n",
      "Name: 3, dtype: int64 messages\n",
      "['And methodology, and data visualization (PowerBI, Tableau, etc.).\\nSalary: * depending on relevant industry experience.\\nA Day In The Life of a Data Engineer I*.'\n",
      " 'A Master’s degree or higher in a relevant field such as computer science, data science, applied statistics, or a quantitative social science field or a bachelor…'\n",
      " 'We are looking for a data engineer who has passion for data integration technologies and comes with data warehousing background.'\n",
      " 'Define long term vision and roadmap for the data science/ML capabilities.\\n2+ years of management experience leading data scientists.']\n",
      "\n",
      "\n",
      "5 has 0    211\n",
      "Name: 5, dtype: int64 messages\n",
      "['Lead workshops, document business requirements.\\nMinimum 9 years of experience in converting functional requirements into technical specifications, and configure…'\n",
      " 'The BI Developer is responsible for all stages of the business intelligence cycle: understanding business objectives, collecting business requirements,…'\n",
      " 'Work with business users and other assigned team members to gather and document business requirements, analyze, design technical solutions.'\n",
      " 'Ability to perform detailed business analysis and design.\\nProduce Ad Hoc Reports to answer business questions quickly and thoroughly.']\n",
      "\n",
      "\n",
      "1 has 0    180\n",
      "Name: 1, dtype: int64 messages\n",
      "['Develop custom data models and algorithms to apply to data sets.\\nMachine Learning – good knowledge of machine learning methods like k-Nearest Neighbors, Naive…'\n",
      " 'Experience putting machine learning models into production.\\nHas strong fundamentals in machine learning and statistics evidenced by a track record of…'\n",
      " 'Experience working with machine learning algorithms to solve classification and clustering problems, perform information retrieval from unstructured and semi…'\n",
      " 'We have an immediate opening for a machine learning engineer with experience in object detection, deep learning, and modeling.\\nPython Flask: 1 year (Required).']\n",
      "\n",
      "\n",
      "0 has 0    146\n",
      "Name: 0, dtype: int64 messages\n",
      "['Backup and Recovery – Create, test and deploy database backup and recovery processes using vender utilities.'\n",
      " 'Perform database administration maintenance activities while maintaining high database system availability and reliability for business applications.'\n",
      " 'Identifying and resolving problems occurring in all database environments including performance related issues (i.e. database & SQL tuning).'\n",
      " 'Maintain Iris (the database system Epic runs on).\\nMaintain the files that allow for Epic client communication with the database.']\n",
      "\n",
      "\n",
      "2 has 0    108\n",
      "Name: 2, dtype: int64 messages\n",
      "['[redacted] Engineering is seeking a React Web Developer to bolster the data-driven design and user experience of our platform.'\n",
      " 'FC Project Manager II, Data Science Our Opportunity: Chewy is hiring a FC Project Manager II, Data Science for a technical role to support our North…'\n",
      " 'Work closely with internal and external team members to develop and build self-service capabilities, and automation, to enable our internal customers to move…'\n",
      " 'Responsibilities will include AEM headful component development and configuration in CRXDE.\\nYou will work with Lead Front End Developers on specification and…']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort clusters by their size, and create a new dataframe with the size and cluster number in sorted order. Maintain other columns\n",
    "size_and_cluster_number = pd.DataFrame(df.groupby(\"kmeans_label\").size().sort_values(ascending=False))\n",
    "\n",
    "# print out 10 messages from n cluster\n",
    "for cluster_number, size in size_and_cluster_number.iterrows():\n",
    "    print(f\"{cluster_number} has {size} messages\")\n",
    "    print(df[df.kmeans_label == cluster_number].sample(4).Description.values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">token_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmeans_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3641</td>\n",
       "      <td>24.938356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4766</td>\n",
       "      <td>26.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3109</td>\n",
       "      <td>28.787037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7529</td>\n",
       "      <td>27.478102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7419</td>\n",
       "      <td>26.402135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5266</td>\n",
       "      <td>24.957346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token_count           \n",
       "                     sum       mean\n",
       "kmeans_label                       \n",
       "0                   3641  24.938356\n",
       "1                   4766  26.477778\n",
       "2                   3109  28.787037\n",
       "3                   7529  27.478102\n",
       "4                   7419  26.402135\n",
       "5                   5266  24.957346"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kmeans_label').agg({\n",
    "    'token_count': ['sum', 'mean']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample questions\n",
    "We can sample around 4k tokens worth of questions. To do this, we shuffle the questions in each cluster, then cut the first ~4k token chunk from each cluster. This should give us ~50% sample ratio on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 has 0    281\n",
      "Name: 4, dtype: int64 messages\n",
      "3 has 0    274\n",
      "Name: 3, dtype: int64 messages\n",
      "5 has 0    211\n",
      "Name: 5, dtype: int64 messages\n",
      "1 has 0    180\n",
      "Name: 1, dtype: int64 messages\n",
      "0 has 0    146\n",
      "Name: 0, dtype: int64 messages\n",
      "2 has 0    108\n",
      "Name: 2, dtype: int64 messages\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def create_doc(messages, max_tokens=3800):\n",
    "    #sample around 125 messages from the cluster\n",
    "    input_doc = '\\n\\n'.join(messages)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens, chunk_overlap=0, separator=\"\\n\\n\")\n",
    "    # Sanity check\n",
    "    split_texts = text_splitter.split_text(input_doc)\n",
    "    \n",
    "    # text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=16000,chunk_overlap=0,separator=\"\\n\\n\")\n",
    "    return split_texts[0]\n",
    "\n",
    "\n",
    "# for clusters, create docs and save in list\n",
    "docs = []\n",
    "for cluster_number, size in size_and_cluster_number.iterrows():\n",
    "    print(f\"{cluster_number} has {size} messages\")\n",
    "    Description = df[df.kmeans_label == cluster_number].Description.values\n",
    "    doc = create_doc(Description)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "map_template_string = \"\"\"The following is a list of texts that have been clustered using K-Means.\n",
    "{questions}\n",
    "\n",
    "Based on this list of questions, please do 3 things: \n",
    "(1) Identify the main theme\n",
    "(2) Give a list of 3 to 5 main sub-themes\n",
    "(3) Give a representitive example text in each sub-theme\n",
    "(4) Estimate the proportion of questions that fall into each theme\n",
    "(5) Share observations on outliers, i.e. questions that do not seem to belong\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"questions\"], template=map_template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_map(input_doc):\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "   \n",
    "    return map_llm_chain.run(questions=input_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Single cluster test with GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_index.token_catcher import Usage\n",
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    gpt_35_test_result = run_map(docs[0])\n",
    "    print(cb)\n",
    "    print(gpt_35_test_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3880"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4 Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_results = []\n",
    "\n",
    "for input_doc in docs:\n",
    "    result=run_map(input_doc)\n",
    "    gpt4_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23889"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 281 messages: \n",
      "\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"We make data science workflows repeatable, scalable, and observable while reducing toil and increasing release velocity.\" These texts may require further analysis to determine their appropriate categorization.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 1 has 274 messages: \n",
      "\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   - Example Text: \"5+ years of relevant experience in report development, data science, business analytics, business intelligence, or comparable data engineering role, including…\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   - Example Text: \"Experience with traditional data warehouse data structures.\"\n",
      "   \n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   - Example Text: \"5+ years management experience building and leading data science teams.\"\n",
      "   \n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   - Example Text: \"Should have strong data analysis.\"\n",
      "   \n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   - Example Text: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience in data science and data engineering: 30%\n",
      "- Experience with specific tools and technologies: 20%\n",
      "- Experience in managing and leading data science teams: 10%\n",
      "- Experience with data analysis and data visualization: 20%\n",
      "- Experience with data pipelines and data integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are no clear outliers in this list of texts. All the texts are related to data science and data engineering experience, with varying levels of specificity in terms of tools, technologies, and management experience.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 2 has 211 messages: \n",
      "\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 3 has 180 messages: \n",
      "\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 4 has 146 messages: \n",
      "\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 5 has 108 messages: \n",
      "\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers in the list that do not seem to belong to any of the main themes. These include texts related to healthcare, government agencies, and education. These outliers make up approximately 10% of the questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "for i, result in enumerate(gpt4_results):\n",
    "\n",
    "    #print size of cluster\n",
    "    print(f\"Cluster {i} has {size_and_cluster_number.iloc[i].values[0]} messages: \\n\")\n",
    "\n",
    "    #print the summary\n",
    "    print(result)\n",
    "\n",
    "    #print separator\n",
    "    print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5-Turbo Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n",
      "Tokens Used: 3928\n",
      "\tPrompt Tokens: 3566\n",
      "\tCompletion Tokens: 362\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.006072999999999999\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   Example: \"10+ years of technical experience in a data science role or equivalent.\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   Example: \"Experience with traditional data warehouse data structures.\"\n",
      "\n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   Example: \"5+ years management experience building and leading data science teams.\"\n",
      "\n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   Example: \"Familiarity with data exploration and data visualization tools, like Tableau, Datorama, etc.\"\n",
      "\n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   Example: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience: 30%\n",
      "- Experience with tools and technologies: 20%\n",
      "- Managing and leading teams: 10%\n",
      "- Data analysis and visualization: 20%\n",
      "- Data pipelines and integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outliers in the list of texts that do not seem to belong to the main theme of data science and data engineering experience. These outliers include texts related to software development, business intelligence, and project management. These texts may have been included in the clustering process due to similarities in keywords or phrases, but they do not align with the main theme.\n",
      "Tokens Used: 7812\n",
      "\tPrompt Tokens: 7152\n",
      "\tCompletion Tokens: 660\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.012048\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "Tokens Used: 11622\n",
      "\tPrompt Tokens: 10691\n",
      "\tCompletion Tokens: 931\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.0178985\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "Tokens Used: 15431\n",
      "\tPrompt Tokens: 14247\n",
      "\tCompletion Tokens: 1184\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.023738500000000003\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "Tokens Used: 18945\n",
      "\tPrompt Tokens: 17473\n",
      "\tCompletion Tokens: 1472\n",
      "Successful Requests: 5\n",
      "Total Cost (USD): $0.029153500000000002\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example text: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example text: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 10% of questions\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example text: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example text: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example text: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers that do not seem to belong to any of the main themes. These include texts related to healthcare, payroll, public health, and bookkeeping. These outliers make up around 10% of the questions.\n"
     ]
    }
   ],
   "source": [
    "gpt35_results = []\n",
    "with get_openai_callback() as cb:\n",
    "    for input_doc in docs:\n",
    "        result=run_map(input_doc)\n",
    "        gpt35_results.append(result)\n",
    "        print(cb)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18945"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 281 messages: \n",
      "\n",
      "Main Theme: Data Science and Analytics\n",
      "\n",
      "Sub-themes:\n",
      "1. Data Management and Governance\n",
      "   - Example text: Incorporate core data management competencies including data governance, data security, and data quality.\n",
      "   - Proportion: 10%\n",
      "\n",
      "2. Collaboration and Teamwork\n",
      "   - Example text: Collaborate with central team data science, insight and CRM teams to employ insight, segmentations and models to improve personalization and targeting of CRM.\n",
      "   - Proportion: 15%\n",
      "\n",
      "3. Data Analysis and Insights\n",
      "   - Example text: Analyze product data to identify problems and ideate product features and process enhancements.\n",
      "   - Proportion: 20%\n",
      "\n",
      "4. Data Infrastructure and Systems\n",
      "   - Example text: Build controls, processes, and systems to ensure SLAs are met to manage and scale data pipelines from internal and external data sources.\n",
      "   - Proportion: 15%\n",
      "\n",
      "5. Data Science Strategy and Leadership\n",
      "   - Example text: Define a clear data science and analytics roadmap.\n",
      "   - Proportion: 10%\n",
      "\n",
      "Observations on outliers: There are a few texts that do not seem to fit into any of the sub-themes, such as \"This position manages direct reports and multiple consultants/contractors including data…\" and \"This team member collaborates with Data Scientists to design tools to train machine learning models using data from across the enterprise and deploy machine…\". These texts may require further analysis to determine their appropriate categorization.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 1 has 274 messages: \n",
      "\n",
      "(1) Main Theme: Data Science and Data Engineering Experience\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Years of experience in data science and data engineering\n",
      "- Experience with specific tools and technologies\n",
      "- Experience in managing and leading data science teams\n",
      "- Experience with data analysis and data visualization\n",
      "- Experience with data pipelines and data integration\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Years of experience in data science and data engineering\n",
      "   Example: \"10+ years of technical experience in a data science role or equivalent.\"\n",
      "\n",
      "- Sub-Theme: Experience with specific tools and technologies\n",
      "   Example: \"Experience with traditional data warehouse data structures.\"\n",
      "\n",
      "- Sub-Theme: Experience in managing and leading data science teams\n",
      "   Example: \"5+ years management experience building and leading data science teams.\"\n",
      "\n",
      "- Sub-Theme: Experience with data analysis and data visualization\n",
      "   Example: \"Familiarity with data exploration and data visualization tools, like Tableau, Datorama, etc.\"\n",
      "\n",
      "- Sub-Theme: Experience with data pipelines and data integration\n",
      "   Example: \"Proven experience in Design & Implementation of end-end data pipelines.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Years of experience: 30%\n",
      "- Experience with tools and technologies: 20%\n",
      "- Managing and leading teams: 10%\n",
      "- Data analysis and visualization: 20%\n",
      "- Data pipelines and integration: 20%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outliers in the list of texts that do not seem to belong to the main theme of data science and data engineering experience. These outliers include texts related to software development, business intelligence, and project management. These texts may have been included in the clustering process due to similarities in keywords or phrases, but they do not align with the main theme.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 2 has 211 messages: \n",
      "\n",
      "Main Theme: Business Intelligence and Data Analysis\n",
      "\n",
      "Sub-themes:\n",
      "1. Business Requirements and Analysis\n",
      "   - Example text: \"Define configuration specifications and business analysis requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Reporting and Dashboard Creation\n",
      "   - Example text: \"Create analytical reports/dashboards to monitor data issues and business processes.\"\n",
      "   - Proportion: 20%\n",
      "\n",
      "3. Data Conversion and Management\n",
      "   - Example text: \"Execute data conversions and provides guidance to junior developers when needed.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Business Process Improvement\n",
      "   - Example text: \"Develop and document improved business processes.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "5. Stakeholder Engagement and Collaboration\n",
      "   - Example text: \"Collaborate with business to review and prioritize business requirements.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "Observations:\n",
      "- Outliers: There are a few texts that mention specific tools or technologies (e.g., SAP Business Objects, Power BI, Jira, etc.), which do not fit neatly into any of the sub-themes. These can be considered outliers.\n",
      "- The main theme of Business Intelligence and Data Analysis is the most prominent, with the majority of the texts falling into this category.\n",
      "- The sub-theme of Reporting and Dashboard Creation is the largest sub-theme, indicating a focus on visualizing and monitoring data.\n",
      "- The proportion of questions in each sub-theme is estimated based on the provided texts and may not be entirely accurate.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 3 has 180 messages: \n",
      "\n",
      "Main Theme: Machine Learning and Data Science\n",
      "\n",
      "Sub-themes:\n",
      "1. Machine Learning Expertise\n",
      "   - Example Text: \"Proficiency with data mining and machine learning.\"\n",
      "   - Proportion: 15%\n",
      "\n",
      "2. Machine Learning Model Deployment\n",
      "   - Example Text: \"Experience deploying machine learning models to production environments.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "3. Machine Learning Frameworks and Tools\n",
      "   - Example Text: \"Excellent understanding of machine learning frameworks (Keras/Tensorflow/PyTorch etc.\"\n",
      "   - Proportion: 10%\n",
      "\n",
      "4. Natural Language Processing and Text Analysis\n",
      "   - Example Text: \"Solve some of the most challenging problems in natural language processing, machine learning, and information retrieval.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "5. Computer Vision and Image Processing\n",
      "   - Example Text: \"Excited by the idea of learning new concepts ranging from embedded integration, computer vision, and machine learning.\"\n",
      "   - Proportion: 5%\n",
      "\n",
      "Observations:\n",
      "- The majority of the questions fall into the main theme of Machine Learning and Data Science.\n",
      "- There are some outliers that do not seem to belong, such as questions about software development experience or job location. These outliers may have been included due to the use of keywords like \"machine learning\" or \"data science\" in the job description.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 4 has 146 messages: \n",
      "\n",
      "(1) Main Theme: Database Administration and Management\n",
      "\n",
      "(2) Sub-Themes:\n",
      "- Database Performance Optimization\n",
      "- Database Security and Access Control\n",
      "- Database Backup and Recovery\n",
      "- Database Design and Schema Management\n",
      "- Database Monitoring and Troubleshooting\n",
      "\n",
      "(3) Representative Examples:\n",
      "- Sub-Theme: Database Performance Optimization\n",
      "Example Text: \"Experience in improving database performance.\"\n",
      "- Sub-Theme: Database Security and Access Control\n",
      "Example Text: \"Secure database by preparing access and control policies and procedures.\"\n",
      "- Sub-Theme: Database Backup and Recovery\n",
      "Example Text: \"Backup and Recovery – Create, test and deploy database backup and recovery processes using vendor utilities.\"\n",
      "\n",
      "(4) Proportion of Questions:\n",
      "- Database Performance Optimization: 15%\n",
      "- Database Security and Access Control: 10%\n",
      "- Database Backup and Recovery: 10%\n",
      "- Database Design and Schema Management: 5%\n",
      "- Database Monitoring and Troubleshooting: 5%\n",
      "\n",
      "(5) Observations on Outliers:\n",
      "There are a few outlier questions that do not seem to fit into any of the main sub-themes, such as questions related to specific technologies like MSFT Azure and AWS Cloud Services. These questions may fall under a separate sub-theme of \"Database Administration with Cloud Technologies.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Cluster 5 has 108 messages: \n",
      "\n",
      "Main Theme: Job Opportunities and Requirements\n",
      "\n",
      "Sub-themes:\n",
      "1. Cloud-hosted business process migration in SAAS implementations\n",
      "   - Example text: \"Preferred candidates will have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "2. Engineering and Software Development\n",
      "   - Example text: \"Collaborate with senior engineers to design features.\"\n",
      "   - Proportion: 10% of questions\n",
      "\n",
      "3. Mental Health Solutions\n",
      "   - Example text: \"Our mission: eliminating every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "4. Retail Data Science and Insights\n",
      "   - Example text: \"84.51° is a retail data science, insights and media company.\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "5. Data Solutions and Big Data Technologies\n",
      "   - Example text: \"Engineering at 84.51° builds software and data solutions that enable our customers and partners to…\"\n",
      "   - Proportion: 5% of questions\n",
      "\n",
      "Observations on Outliers:\n",
      "There are a few outliers that do not seem to belong to any of the main themes. These include texts related to healthcare, payroll, public health, and bookkeeping. These outliers make up around 10% of the questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "for i, result in enumerate(gpt35_results):\n",
    "\n",
    "    #print size of cluster\n",
    "    print(f\"Cluster {i} has {size_and_cluster_number.iloc[i].values[0]} messages: \\n\")\n",
    "\n",
    "    #print the summary\n",
    "    print(result)\n",
    "\n",
    "    #print separator\n",
    "    print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send all cases through Map Reduce chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "input_doc = '\\n\\n'.join(docs)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=4000,chunk_overlap=0,separator=\"\\n\\n\")\n",
    "# Sanity check\n",
    "len(text_splitter.split_text(input_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_template_string = \"\"\"The following is a list of texts that have been clustered using K-Means\n",
    "{questions}\n",
    "\n",
    "Based on this list of texts, please do 4 things: \n",
    "(1) identify the main themes \n",
    "(2) give a represntitive example question in each theme\n",
    "(3) estimate the proportion of questions that fall into each theme\n",
    "(4) share observations on outliers, i.e. questions that do not seem to belong\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_template_string = template = \"\"\"The following is a list of summaries for questions entered into a Q+A system:\n",
    "{question_summaries}\n",
    "\n",
    "Take these and distill it into a final, consolidated list with: \n",
    "(1) the main question themes \n",
    "(2) two represntitive example questions in each theme\n",
    "(3) estimate the proportion of questions that fall into each theme\n",
    "(4) a summary of outliers\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "MAP_PROMPT = PromptTemplate(input_variables=[\"questions\"], template=map_template_string)\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"question_summaries\"], template=reduce_template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.chains import (\n",
    "                StuffDocumentsChain,\n",
    "                LLMChain,\n",
    "                ReduceDocumentsChain,\n",
    "                MapReduceDocumentsChain,\n",
    "            )\n",
    "\n",
    "\n",
    "def run_map_reduce(input_doc, model, MAP_PROMPT, REDUCE_PROMPT):\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=model, temperature=0)\n",
    "    map_llm_chain = LLMChain(llm=llm, prompt=MAP_PROMPT)\n",
    "\n",
    "    llm = ChatOpenAI(model_name=model, temperature=0)\n",
    "    reduce_llm_chain = LLMChain(llm=llm, prompt=REDUCE_PROMPT)\n",
    "\n",
    "    # Takes a list of documents and combines them into a single string\n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "            llm_chain=reduce_llm_chain,\n",
    "            document_variable_name=\"question_summaries\")\n",
    "    \n",
    "    # Combines and iteravely reduces the mapped documents \n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `combine_documents_chain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=4000)\n",
    "\n",
    "    # Combining documents by mapping a chain over them, then combining results\n",
    "    combine_documents = MapReduceDocumentsChain(\n",
    "        # Map chain\n",
    "        llm_chain=map_llm_chain,\n",
    "        # Reduce chain\n",
    "        reduce_documents_chain=reduce_documents_chain,\n",
    "        # The variable name in the llm_chain to put the documents in\n",
    "        document_variable_name=\"questions\",\n",
    "        # Return the results of the map steps in the output\n",
    "        ### Bug: this currently does not work ###\n",
    "        return_intermediate_steps=False)\n",
    "        \n",
    "    # Define Map=Reduce\n",
    "    map_reduce = MapReduceChain(\n",
    "        # Chain to combine documents\n",
    "        combine_documents_chain=combine_documents,\n",
    "        # Splitter to use for initial split\n",
    "        text_splitter=text_splitter)\n",
    "    \n",
    "    return map_reduce.run(input_text=input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117588"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20346"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 5059\n",
      "\tPrompt Tokens: 4146\n",
      "\tCompletion Tokens: 913\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.17915999999999999\n",
      "\n",
      "Cluster: 0:\n",
      "(1) Main Question Themes:\n",
      "   - Data Science Strategy and Management\n",
      "   - Data Analysis and Insights\n",
      "   - Data Engineering and Infrastructure\n",
      "   - Collaboration and Teamwork\n",
      "   - Data Governance and Security\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Data Science Strategy and Management: \n",
      "     1. \"How do you define and execute a data science strategy that ensures our organization's success?\"\n",
      "     2. \"What are the key elements in setting up a successful data science workflow?\"\n",
      "   - Data Analysis and Insights: \n",
      "     1. \"How do you analyze product data to identify problems and ideate product features?\"\n",
      "     2. \"What methods do you use to turn raw data into actionable insights?\"\n",
      "   - Data Engineering and Infrastructure: \n",
      "     1. \"How do you manage and scale data pipelines from internal and external data sources?\"\n",
      "     2. \"What are the best practices for ensuring data quality in data extraction and transformation processes?\"\n",
      "   - Collaboration and Teamwork: \n",
      "     1. \"How do you collaborate with software developers, other data engineers, and database managers to automate repeatable data tasks?\"\n",
      "     2. \"What strategies do you use to ensure effective collaboration between data science teams and business users?\"\n",
      "   - Data Governance and Security: \n",
      "     1. \"How do you incorporate core data management competencies including data governance, data security, and data quality?\"\n",
      "     2. \"What measures do you take to ensure data integrity and compliance with data protection regulations?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Data Science Strategy and Management: 30%\n",
      "   - Data Analysis and Insights: 25%\n",
      "   - Data Engineering and Infrastructure: 20%\n",
      "   - Collaboration and Teamwork: 15%\n",
      "   - Data Governance and Security: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions focus on specific sectors or applications of data science, such as healthcare or marketing, which do not fit neatly into the main themes.\n",
      "   - Some questions mention specific locations or eligibility requirements, which are not related to the main themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 9853\n",
      "\tPrompt Tokens: 8175\n",
      "\tCompletion Tokens: 1678\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.34592999999999996\n",
      "\n",
      "Cluster: 1:\n",
      "(1) Main Question Themes:\n",
      "   - Data Science Experience\n",
      "   - Data Engineering Skills\n",
      "   - Management Experience\n",
      "   - Education\n",
      "   - Project Experience\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Data Science Experience: \n",
      "     1. \"How many years of experience do you have in a data science role?\"\n",
      "     2. \"Can you describe your experience in data analytics?\"\n",
      "   - Data Engineering Skills: \n",
      "     1. \"Do you have experience working with SQL, Hadoop, Spark, or AWS?\"\n",
      "     2. \"Can you list the data engineering technologies you are proficient in?\"\n",
      "   - Management Experience: \n",
      "     1. \"Have you ever managed or led a data science or data engineering team?\"\n",
      "     2. \"Can you describe your experience in leading data projects?\"\n",
      "   - Education: \n",
      "     1. \"What is your highest level of education in a field related to data science or data engineering?\"\n",
      "     2. \"Do you hold any degrees or certifications in data science or data engineering?\"\n",
      "   - Project Experience: \n",
      "     1. \"Can you describe a project where you developed a data pipeline or performed data analysis?\"\n",
      "     2. \"What types of data integration projects have you worked on?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Data Science Experience: 40%\n",
      "   - Data Engineering Skills: 30%\n",
      "   - Management Experience: 10%\n",
      "   - Education: 10%\n",
      "   - Project Experience: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific industries or business domains, such as finance or retail, which do not fit neatly into the main themes.\n",
      "   - Some questions mention specific tools or technologies that are not commonly used in data science or data engineering, such as Confluent Kafka or Oracle 12C.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 14877\n",
      "\tPrompt Tokens: 12285\n",
      "\tCompletion Tokens: 2592\n",
      "Successful Requests: 6\n",
      "Total Cost (USD): $0.5240699999999999\n",
      "\n",
      "Cluster: 2:\n",
      "(1) Main Question Themes:\n",
      "   - Business Intelligence Development\n",
      "   - Business Analysis\n",
      "   - Project Management\n",
      "   - Data Analysis\n",
      "   - Client/Stakeholder Interaction\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Business Intelligence Development: \n",
      "     1. \"What experience do you have in creating analytical reports/dashboards to monitor data issues and business processes?\"\n",
      "     2. \"Can you describe your experience in maintaining business intelligence solutions, reports, dashboards, and scorecards?\"\n",
      "   - Business Analysis: \n",
      "     1. \"Can you provide an example of a time when you had to define configuration specifications and business analysis requirements for a project?\"\n",
      "     2. \"How do you go about translating business needs into technical requirements?\"\n",
      "   - Project Management: \n",
      "     1. \"What experience do you have in leading the process for identifying and gathering appropriate business requirements to create necessary solutions that satisfy business needs?\"\n",
      "     2. \"Can you describe a project where you ensured the outcomes met the business needs?\"\n",
      "   - Data Analysis: \n",
      "     1. \"Can you describe a time when you had to analyze data to draw business-relevant conclusions and provide data solutions?\"\n",
      "     2. \"How do you go about monitoring data issues in your role?\"\n",
      "   - Client/Stakeholder Interaction: \n",
      "     1. \"Can you provide an example of a time when you had to work with business users and other team members to gather and document business requirements?\"\n",
      "     2. \"How do you ensure you understand the business needs of your clients or stakeholders?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Business Intelligence Development: 30%\n",
      "   - Business Analysis: 25%\n",
      "   - Project Management: 20%\n",
      "   - Data Analysis: 15%\n",
      "   - Client/Stakeholder Interaction: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions focus on specific software or tools such as SAP Business Objects suite, Power BI, Jira, and Informatica mappings/workflows, which are more specific technical skills rather than overarching themes.\n",
      "   - Some questions mention experience requirements, which are not thematic but rather specific job requirements.\n",
      "   - Some questions mention remote work and flexibility, which are more about work conditions rather than job roles or responsibilities.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 19897\n",
      "\tPrompt Tokens: 16317\n",
      "\tCompletion Tokens: 3580\n",
      "Successful Requests: 8\n",
      "Total Cost (USD): $0.70431\n",
      "\n",
      "Cluster: 3:\n",
      "(1) Main Question Themes:\n",
      "   - Machine Learning Model Development and Deployment\n",
      "   - Data Science and Analytics\n",
      "   - AI and Deep Learning Techniques\n",
      "   - Tools and Frameworks for Machine Learning\n",
      "   - Experience and Expertise in Machine Learning\n",
      "   - Research and Innovation in Machine Learning\n",
      "\n",
      "(2) Two Representative Example Questions in Each Theme:\n",
      "   - Machine Learning Model Development and Deployment: \n",
      "     1. \"What experience do you have in developing and deploying machine learning models for ad recommendation?\"\n",
      "     2. \"Can you explain your process for developing and deploying a machine learning model?\"\n",
      "   - Data Science and Analytics: \n",
      "     1. \"Can you provide examples of your proficiency with data mining and machine learning?\"\n",
      "     2. \"How have you used data science and analytics in your previous roles?\"\n",
      "   - AI and Deep Learning Techniques: \n",
      "     1. \"What is your understanding of various advanced analytical and machine learning methods?\"\n",
      "     2. \"Can you explain how you have applied AI and deep learning techniques in your work?\"\n",
      "   - Tools and Frameworks for Machine Learning: \n",
      "     1. \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\"\n",
      "     2. \"What tools and frameworks do you typically use for machine learning projects?\"\n",
      "   - Experience and Expertise in Machine Learning: \n",
      "     1. \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\"\n",
      "     2. \"What is your level of expertise in machine learning?\"\n",
      "   - Research and Innovation in Machine Learning: \n",
      "     1. \"Have you published any work at major machine learning conferences or in major scientific journals?\"\n",
      "     2. \"Can you discuss any innovative approaches you've taken in your machine learning research?\"\n",
      "\n",
      "(3) Estimated Proportion of Questions That Fall into Each Theme:\n",
      "   - Machine Learning Model Development and Deployment: 30%\n",
      "   - Data Science and Analytics: 20%\n",
      "   - AI and Deep Learning Techniques: 15%\n",
      "   - Tools and Frameworks for Machine Learning: 15%\n",
      "   - Experience and Expertise in Machine Learning: 10%\n",
      "   - Research and Innovation in Machine Learning: 10%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific industries or applications, such as \"computer vision\", \"natural language processing\", or \"ad recommendation\", which are not common across all questions.\n",
      "   - Some questions mention specific tools or languages, such as \"Python\", \"TensorFlow\", or \"SQL\", which are not common across all questions.\n",
      "   - Some questions mention specific experience requirements, such as \"Python Flask: 1 year (Required)\" or \"Machine learning: 1 year (Preferred)\", which are not common across all questions.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 24874\n",
      "\tPrompt Tokens: 20338\n",
      "\tCompletion Tokens: 4536\n",
      "Successful Requests: 10\n",
      "Total Cost (USD): $0.8823\n",
      "\n",
      "Cluster: 4:\n",
      "(1) Main Question Themes:\n",
      "   - Database Administration and Maintenance\n",
      "   - Database Security\n",
      "   - Database Performance Optimization\n",
      "   - Database Troubleshooting\n",
      "   - Database Backup and Recovery\n",
      "   - Database Design and Development\n",
      "   - Database Software and Tools\n",
      "   - Database Experience and Skills\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "   - Database Administration and Maintenance: \n",
      "     1. \"What is your experience in database administration and maintenance?\"\n",
      "     2. \"How do you manage routine database maintenance tasks?\"\n",
      "   - Database Security: \n",
      "     1. \"How do you ensure the security of a database?\"\n",
      "     2. \"What measures do you take to prevent unauthorized access to databases?\"\n",
      "   - Database Performance Optimization: \n",
      "     1. \"What strategies do you use to optimize database performance?\"\n",
      "     2. \"How do you handle performance issues in a database?\"\n",
      "   - Database Troubleshooting: \n",
      "     1. \"Can you describe a time when you had to troubleshoot a complex database issue?\"\n",
      "     2. \"What steps do you take to diagnose and resolve database problems?\"\n",
      "   - Database Backup and Recovery: \n",
      "     1. \"What is your approach to database backup and recovery?\"\n",
      "     2. \"How do you plan and execute a database recovery strategy?\"\n",
      "   - Database Design and Development: \n",
      "     1. \"Can you describe a database you have designed and developed?\"\n",
      "     2. \"What principles do you follow when designing a new database?\"\n",
      "   - Database Software and Tools: \n",
      "     1. \"What database software and tools are you proficient in?\"\n",
      "     2. \"How do you use database management tools to improve efficiency?\"\n",
      "   - Database Experience and Skills: \n",
      "     1. \"What is your experience and skill level with SQL, Oracle, and other databases?\"\n",
      "     2. \"Can you share your experience with database programming languages?\"\n",
      "\n",
      "(3) Estimated Proportions:\n",
      "   - Database Administration and Maintenance: 25%\n",
      "   - Database Security: 10%\n",
      "   - Database Performance Optimization: 15%\n",
      "   - Database Troubleshooting: 10%\n",
      "   - Database Backup and Recovery: 10%\n",
      "   - Database Design and Development: 15%\n",
      "   - Database Software and Tools: 10%\n",
      "   - Database Experience and Skills: 5%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "   - Some questions mention specific database technologies like AWS, Azure, MongoDB, PostgreSQL, which do not fit neatly into the identified themes. These could be considered outliers or could form a separate theme around specific database technologies.\n",
      "   - Some questions mention specific years of experience or certifications, which do not fit neatly into the identified themes. These could be considered outliers or could form a separate theme around qualifications and experience.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 29513\n",
      "\tPrompt Tokens: 24054\n",
      "\tCompletion Tokens: 5459\n",
      "Successful Requests: 12\n",
      "Total Cost (USD): $1.04916\n",
      "\n",
      "Cluster: 5:\n",
      "(1) Main Question Themes:\n",
      "- Software Engineering and Development\n",
      "- Data Science and Analytics\n",
      "- Business Process and Strategy\n",
      "- Health and Medical Data Management\n",
      "- Cloud and SAAS Implementations\n",
      "- Machine Learning and AI\n",
      "- Job Application and Recruitment\n",
      "\n",
      "(2) Representative Example Questions in Each Theme:\n",
      "- Software Engineering and Development: \n",
      "  - \"What is your experience with designing features in collaboration with senior engineers?\"\n",
      "  - \"Can you describe a project where you had to use your knowledge of software development principles?\"\n",
      "- Data Science and Analytics: \n",
      "  - \"Can you describe a time when you identified data quality issues and implemented fixes?\"\n",
      "  - \"How have you used data analytics to drive business decisions?\"\n",
      "- Business Process and Strategy: \n",
      "  - \"Have you ever led teams of 25+ engineers and managed managers?\"\n",
      "  - \"Can you provide an example of a strategic business decision you made and its outcome?\"\n",
      "- Health and Medical Data Management: \n",
      "  - \"How have you used business intelligence applications to enhance clinical & business decision-making capabilities?\"\n",
      "  - \"Can you describe a project where you had to manage health or medical data?\"\n",
      "- Cloud and SAAS Implementations: \n",
      "  - \"Do you have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations?\"\n",
      "  - \"Can you describe a time when you had to troubleshoot a problem in a cloud-based system?\"\n",
      "- Machine Learning and AI: \n",
      "  - \"Can you provide an example of a project where you used machine learning to improve a business process?\"\n",
      "  - \"How have you used AI to solve a complex problem?\"\n",
      "- Job Application and Recruitment: \n",
      "  - \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\"\n",
      "  - \"Can you describe your experience with remote work?\"\n",
      "\n",
      "(3) Estimated Proportion of Questions That Fall into Each Theme:\n",
      "- Software Engineering and Development: 30%\n",
      "- Data Science and Analytics: 25%\n",
      "- Business Process and Strategy: 15%\n",
      "- Health and Medical Data Management: 10%\n",
      "- Cloud and SAAS Implementations: 10%\n",
      "- Machine Learning and AI: 5%\n",
      "- Job Application and Recruitment: 5%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "A few outliers were identified that did not fit into the main themes. These included advertisements for courses and fragments of job postings. These outliers did not provide complete or relevant information and were not included in the main themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_reduce_gpt4_res = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for i in range(len(docs)):\n",
    "        result = run_map_reduce(docs[i], \"gpt-4\",MAP_PROMPT, REDUCE_PROMPT)\n",
    "        map_reduce_gpt4_res.append(result)\n",
    "        print(cb)\n",
    "        print(f\"\\nCluster: {i}:\")\n",
    "        print(result)\n",
    "        print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29513"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 4575\n",
      "\tPrompt Tokens: 3930\n",
      "\tCompletion Tokens: 645\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0071849999999999995\n",
      "\n",
      "Cluster: 0:\n",
      "(1) Main Question Themes:\n",
      "- Data Science Strategy and Leadership\n",
      "- Data Management and Quality\n",
      "- Collaboration and Teamwork\n",
      "- Data Analysis and Insights\n",
      "- Data Infrastructure and Tools\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Data Science Strategy and Leadership:\n",
      "  - \"How can we define and execute a data science and analytics roadmap?\"\n",
      "  - \"What are the best practices for building a data-driven culture within an organization?\"\n",
      "\n",
      "- Data Management and Quality:\n",
      "  - \"How can we ensure data governance, data security, and data quality?\"\n",
      "  - \"What are the key steps in data cleaning and preprocessing to improve data quality?\"\n",
      "\n",
      "- Collaboration and Teamwork:\n",
      "  - \"How can we collaborate with other teams to turn data into critical information and knowledge?\"\n",
      "  - \"What are effective strategies for fostering cross-functional collaboration in data science projects?\"\n",
      "\n",
      "- Data Analysis and Insights:\n",
      "  - \"How can we analyze product data to identify problems and ideate product features?\"\n",
      "  - \"What are the best techniques for extracting actionable insights from large datasets?\"\n",
      "\n",
      "- Data Infrastructure and Tools:\n",
      "  - \"How can we design and build modern data pipelines and data service APIs?\"\n",
      "  - \"What are the recommended tools and technologies for scalable data storage and processing?\"\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Data Science Strategy and Leadership: 15%\n",
      "- Data Management and Quality: 20%\n",
      "- Collaboration and Teamwork: 15%\n",
      "- Data Analysis and Insights: 25%\n",
      "- Data Infrastructure and Tools: 25%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are a few questions that do not fit into any of the main themes, suggesting they may be more specific to the organization or context in which the texts were clustered. These outliers include questions like \"Teach the broader data science team new tools and techniques\" and \"Support discovery of business problems.\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 9040\n",
      "\tPrompt Tokens: 7815\n",
      "\tCompletion Tokens: 1225\n",
      "Successful Requests: 4\n",
      "Total Cost (USD): $0.0141725\n",
      "\n",
      "Cluster: 1:\n",
      "Main question themes:\n",
      "1. Experience and qualifications in data science and analytics\n",
      "2. Data engineering and data pipelines\n",
      "3. Data analysis and data visualization\n",
      "4. Technical skills and tools\n",
      "\n",
      "Representative example questions in each theme:\n",
      "1. Experience and qualifications in data science and analytics:\n",
      "- \"Do you have at least 5 years of experience in data science or a related field?\"\n",
      "- \"What qualifications do you have in data science and analytics?\"\n",
      "\n",
      "2. Data engineering and data pipelines:\n",
      "- \"Have you worked on designing and implementing data pipelines?\"\n",
      "- \"What tools and technologies have you used for data engineering?\"\n",
      "\n",
      "3. Data analysis and data visualization:\n",
      "- \"Are you proficient in data analysis and data visualization techniques?\"\n",
      "- \"Can you provide examples of data analysis and visualization projects you have worked on?\"\n",
      "\n",
      "4. Technical skills and tools:\n",
      "- \"Do you have experience with SQL, Python, and cloud technologies?\"\n",
      "- \"What programming languages and tools are you proficient in for data analysis?\"\n",
      "\n",
      "Proportion of questions that fall into each theme:\n",
      "1. Experience and qualifications in data science and analytics: Approximately 30% of the questions.\n",
      "2. Data engineering and data pipelines: Approximately 20% of the questions.\n",
      "3. Data analysis and data visualization: Approximately 15% of the questions.\n",
      "4. Technical skills and tools: Approximately 15% of the questions.\n",
      "\n",
      "Summary of outliers:\n",
      "There are a few questions that do not fit into any specific theme, such as inquiries about management experience, agile methodology, and specific software or technology experience. These questions may be more specific to certain job roles or industries and are considered outliers in the overall question themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 13464\n",
      "\tPrompt Tokens: 11697\n",
      "\tCompletion Tokens: 1767\n",
      "Successful Requests: 6\n",
      "Total Cost (USD): $0.021079499999999998\n",
      "\n",
      "Cluster: 2:\n",
      "(1) Main Question Themes:\n",
      "- Business Intelligence Development\n",
      "- Business Analysis and Requirements Gathering\n",
      "- Data Analysis and Reporting\n",
      "- Project Management and Process Improvement\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Business Intelligence Development:\n",
      "  - \"As a Business Intelligence Developer, what are your responsibilities in creating analytical reports and dashboards?\"\n",
      "  - \"How do you ensure the accuracy and reliability of the data used in your analytical reports and dashboards?\"\n",
      "\n",
      "- Business Analysis and Requirements Gathering:\n",
      "  - \"How do you gather and document business requirements for business processes and reports?\"\n",
      "  - \"What techniques do you use to prioritize and validate business requirements?\"\n",
      "\n",
      "- Data Analysis and Reporting:\n",
      "  - \"What experience do you have in analyzing data to draw business-relevant conclusions and creating analytical reports?\"\n",
      "  - \"Can you provide an example of a complex data analysis project you have worked on and the insights you derived from it?\"\n",
      "\n",
      "- Project Management and Process Improvement:\n",
      "  - \"How do you lead the process for identifying and gathering appropriate business requirements to create necessary solutions?\"\n",
      "  - \"What strategies do you employ to ensure successful project delivery and continuous process improvement?\"\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Business Intelligence Development: 20%\n",
      "- Business Analysis and Requirements Gathering: 30%\n",
      "- Data Analysis and Reporting: 30%\n",
      "- Project Management and Process Improvement: 20%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are no clear outliers in this list of questions. However, some questions may overlap across themes, such as questions related to data analysis and reporting that also involve business intelligence development.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 18288\n",
      "\tPrompt Tokens: 15756\n",
      "\tCompletion Tokens: 2532\n",
      "Successful Requests: 8\n",
      "Total Cost (USD): $0.028697999999999998\n",
      "\n",
      "Cluster: 3:\n",
      "(1) Main Question Themes:\n",
      "a) Machine Learning Expertise\n",
      "b) Data Science and Analytics\n",
      "c) AI and ML Applications\n",
      "d) Machine Learning Infrastructure\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "a) Machine Learning Expertise:\n",
      "- What is your experience with modern machine learning theories and frameworks?\n",
      "- Can you provide an example of a machine learning model you have developed and deployed?\n",
      "\n",
      "b) Data Science and Analytics:\n",
      "- How would you approach solving a classification or clustering problem using machine learning algorithms?\n",
      "- Can you explain the concept of feature engineering and its importance in machine learning?\n",
      "\n",
      "c) AI and ML Applications:\n",
      "- How would you use machine learning to deliver actionable insights and accurate predictions in strategic communications?\n",
      "- Can you describe a project where you applied machine learning to improve ad recommendation?\n",
      "\n",
      "d) Machine Learning Infrastructure:\n",
      "- How would you scale and manage machine learning models in a production environment?\n",
      "- Can you explain the process of developing a hosting platform for machine learning models?\n",
      "\n",
      "(3) Proportion of Questions in Each Theme:\n",
      "a) Machine Learning Expertise: 30%\n",
      "b) Data Science and Analytics: 25%\n",
      "c) AI and ML Applications: 30%\n",
      "d) Machine Learning Infrastructure: 15%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "There are a few questions that do not fit into any specific theme, such as inquiries about publications at major machine learning conferences or in major scientific journals, and questions about free training and placement opportunities in data science. These questions may be more specific or niche in nature and may not align with the broader themes identified.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 22995\n",
      "\tPrompt Tokens: 19710\n",
      "\tCompletion Tokens: 3285\n",
      "Successful Requests: 10\n",
      "Total Cost (USD): $0.036135\n",
      "\n",
      "Cluster: 4:\n",
      "(1) Main Question Themes:\n",
      "- Database administration and management\n",
      "- Database performance optimization\n",
      "- Database security and access control\n",
      "- Database backup and recovery\n",
      "- Database design and schema\n",
      "- Database troubleshooting and problem-solving\n",
      "- Cloud database technologies\n",
      "\n",
      "(2) Representative Example Questions:\n",
      "- Database administration and management:\n",
      "  - What are the responsibilities of a database administrator?\n",
      "  - How can database performance be monitored and managed effectively?\n",
      "- Database performance optimization:\n",
      "  - How can database performance be improved?\n",
      "  - What are the common bottlenecks that affect database performance?\n",
      "- Database security and access control:\n",
      "  - What measures can be taken to secure a database?\n",
      "  - How can user access and permissions be managed in a database?\n",
      "- Database backup and recovery:\n",
      "  - What are the best practices for database backup and recovery?\n",
      "  - How can data integrity be ensured during the backup and recovery process?\n",
      "- Database design and schema:\n",
      "  - How can a database schema be designed for optimal performance?\n",
      "  - What factors should be considered when designing a database schema?\n",
      "- Database troubleshooting and problem-solving:\n",
      "  - How can database performance issues be diagnosed and resolved?\n",
      "  - What are the common techniques for troubleshooting database problems?\n",
      "- Cloud database technologies:\n",
      "  - What are the advantages and disadvantages of using cloud databases?\n",
      "  - How can data migration to a cloud database be performed efficiently?\n",
      "\n",
      "(3) Proportion of Questions:\n",
      "- Database administration and management: 20%\n",
      "- Database performance optimization: 15%\n",
      "- Database security and access control: 10%\n",
      "- Database backup and recovery: 10%\n",
      "- Database design and schema: 10%\n",
      "- Database troubleshooting and problem-solving: 20%\n",
      "- Cloud database technologies: 15%\n",
      "\n",
      "(4) Summary of Outliers:\n",
      "- There are a few outlier questions that do not seem to belong to any specific theme, such as \"Pay rate is very flexible!\" and \"Exciting opportunity for recent college grads!\" These questions may be related to job postings or specific opportunities rather than general database topics. These outliers should be disregarded as they do not contribute to the main question themes.\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n",
      "Tokens Used: 27171\n",
      "\tPrompt Tokens: 23273\n",
      "\tCompletion Tokens: 3898\n",
      "Successful Requests: 12\n",
      "Total Cost (USD): $0.0427055\n",
      "\n",
      "Cluster: 5:\n",
      "Main Question Themes:\n",
      "1. Job Descriptions/Requirements\n",
      "2. Company Information\n",
      "3. Technical Skills/Experience\n",
      "4. Data Science/Analytics\n",
      "\n",
      "Representative Example Questions:\n",
      "1. Job Descriptions/Requirements:\n",
      "   - \"Do you have prior experience in implementing Cloud-hosted business process migration in Software as a Service (SAAS) implementations?\"\n",
      "   - \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\"\n",
      "\n",
      "2. Company Information:\n",
      "   - \"What is the mission of Spring Health?\"\n",
      "   - \"What is the annual base salary range for this position?\"\n",
      "\n",
      "3. Technical Skills/Experience:\n",
      "   - \"Do you have experience with Python?\"\n",
      "   - \"Do you have experience in front-end web development?\"\n",
      "\n",
      "4. Data Science/Analytics:\n",
      "   - \"What data solutions and technologies do you use at 84.51°?\"\n",
      "   - \"What statistical modeling techniques are commonly used in your data analysis process?\"\n",
      "\n",
      "Proportion of Questions:\n",
      "1. Job Descriptions/Requirements: Approximately 20% of the questions fall into this theme.\n",
      "2. Company Information: Approximately 10% of the questions fall into this theme.\n",
      "3. Technical Skills/Experience: Approximately 15% of the questions fall into this theme.\n",
      "4. Data Science/Analytics: Approximately 10% of the questions fall into this theme.\n",
      "\n",
      "Summary of Outliers:\n",
      "There are a few questions that do not fit into any specific theme. These outliers may be related to specific job postings or may be unrelated to the main themes identified. Examples of such questions include \"Are you open/looking for a new contract opportunity for a Data Engineer remote role?\" and \"What is the annual base salary range for this position?\"\n",
      "\n",
      "===============================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_reduce_gpt35_res = []\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    for i in range(len(docs)):\n",
    "        result = run_map_reduce(docs[i], \"gpt-3.5-turbo\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "        map_reduce_gpt35_res.append(result)\n",
    "        print(cb)\n",
    "        print(f\"\\nCluster: {i}:\")\n",
    "        print(result)\n",
    "        print(\"\\n===============================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27171"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "input_doc = '\\n\\n'.join(docs)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=4000,chunk_overlap=0,separator=\"\\n\\n\")\n",
    "# Sanity check\n",
    "len(text_splitter.split_text(input_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Topic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template_string = template = \"\"\"The following is a list of summaries:\n",
    "{question_summaries}\n",
    "\n",
    "Take these and distill it into a final, consolidated list with: \n",
    "(1) the top 5 texts related to AI and ML applications.\n",
    "(2) estimate the proportion of each question\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "REDUCE_PROMPT = PromptTemplate(input_variables=[\"question_summaries\"], template=reduce_template_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 717\n",
      "\tPrompt Tokens: 482\n",
      "\tCompletion Tokens: 235\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.028559999999999995\n",
      "(1) Top 5 Texts Related to AI and ML Applications:\n",
      "   - \"What experience do you have in developing and deploying machine learning models for ad recommendation?\"\n",
      "   - \"Can you provide examples of your proficiency with data mining and machine learning?\"\n",
      "   - \"What is your understanding of various advanced analytical and machine learning methods?\"\n",
      "   - \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\"\n",
      "   - \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\"\n",
      "\n",
      "(2) Estimated Proportion of Each Question:\n",
      "   - \"What experience do you have in developing and deploying machine learning models for ad recommendation?\" - 30%\n",
      "   - \"Can you provide examples of your proficiency with data mining and machine learning?\" - 20%\n",
      "   - \"What is your understanding of various advanced analytical and machine learning methods?\" - 15%\n",
      "   - \"Do you have experience with machine learning frameworks such as PyTorch or TensorFlow/Keras?\" - 15%\n",
      "   - \"Can you describe your industry or research experience in data analytics, machine learning, and software development?\" - 10%\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = run_map_reduce(docs[3], \"gpt-4\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = Usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 610\n",
      "\tPrompt Tokens: 509\n",
      "\tCompletion Tokens: 101\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0009655000000000001\n",
      "(1) The top 5 texts related to AI and ML applications are:\n",
      "- Strategic Communications\n",
      "- Ad Recommendation\n",
      "- Natural Language Processing\n",
      "- Computer Vision\n",
      "- Image Processing\n",
      "\n",
      "(2) The estimated proportion of each question is:\n",
      "- Machine Learning Expertise: 30%\n",
      "- Data Science and Analytics: 25%\n",
      "- AI and ML Applications: 30%\n",
      "- Machine Learning Infrastructure: 15%\n",
      "- Outliers: 0% (since they do not fit into any specific theme)\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = run_map_reduce(docs[3], \"gpt-3.5-turbo\", MAP_PROMPT, REDUCE_PROMPT)\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.total_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
